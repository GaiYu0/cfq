{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import *\n",
    "\n",
    "from nltk.parse import stanford, corenlp\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complexityMeasures',\n",
       " 'expectedResponse',\n",
       " 'expectedResponseWithMids',\n",
       " 'index',\n",
       " 'question',\n",
       " 'questionPatternModEntities',\n",
       " 'questionTemplate',\n",
       " 'questionWithBrackets',\n",
       " 'questionWithMids',\n",
       " 'ruleIds',\n",
       " 'ruleTree',\n",
       " 'sparql',\n",
       " 'sparqlPattern',\n",
       " 'sparqlPatternModEntities']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = '/data/yu_gai/cfq'\n",
    "output_dir = '/work/yu_gai/cfq/data/cfq'\n",
    "\n",
    "df = sqlCtx.read.parquet(f'{input_dir}/dataset.parquet').sort('index').persist()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(q):\n",
    "    for s in [\n",
    "        'art director',\n",
    "        'country of nationality',\n",
    "        'costume designer',\n",
    "        'executive producer',\n",
    "        'executive produce',\n",
    "        'executive produced',\n",
    "        'film director',\n",
    "        'film distributor',\n",
    "        'film editor',\n",
    "        'film producer',\n",
    "        'production company',\n",
    "    ]:\n",
    "        q = q.replace(s, s.replace(' ', ''))\n",
    "    return q\n",
    "\n",
    "df = df.withColumn('questionPatternModEntities', udf(replace, StringType())('questionPatternModEntities')).persist()\n",
    "df.rdd.map(lambda r: len(r['questionPatternModEntities'].split(' ')) == len(r['questionTemplate'].split(' '))).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = df.rdd.map(lambda r: r['questionTemplate'].replace('[', '').replace(']', '').replace('VP_SIMPLE', 'do').replace('ADJECTIVE_SIMPLE', 'good')).distinct().map(lambda r: next(parser.raw_parse(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ROOT                                                              \n",
      "                        |                                                                 \n",
      "                        S                                                                \n",
      "                        |                                                                 \n",
      "                        VP                                                               \n",
      "  ______________________|___________________________                                      \n",
      " |                                                 SBAR                                  \n",
      " |                                                  |                                     \n",
      " |                                                  S                                    \n",
      " |                       ___________________________|____________                         \n",
      " |                      NP                                       VP                      \n",
      " |           ___________|_______________         ________________|______________          \n",
      " |          NP          |       |       |       |   |    |   |   |   |          NP       \n",
      " |     _____|___        |       |       |       |   |    |   |   |   |     _____|____     \n",
      "VBD   NN       POS      NN      CC      NN     VBP  ,   VBP  ,   CC VBP   NN    CC   NN  \n",
      " |    |         |       |       |       |       |   |    |   |   |   |    |     |    |    \n",
      "Did entity      's ROLE_SIMPLE and ROLE_SIMPLE  do  ,    do  ,  and  do entity and entity\n",
      "\n",
      "                             ROOT                                                \n",
      "                              |                                                   \n",
      "                              SQ                                                 \n",
      "  ____________________________|________                                           \n",
      " |    |                                VP                                        \n",
      " |    |      __________________________|_______                                   \n",
      " |    |     |                                  NP                                \n",
      " |    |     |           _______________________|_______                           \n",
      " |    NP    |          NP                             NML                        \n",
      " |    |     |    ______|______          _______________|___________________       \n",
      "VBD   NN   VBP  DT     NN    POS       NN      ,       NN      ,   CC      NN    \n",
      " |    |     |   |      |      |        |       |       |       |   |       |      \n",
      "Did entity  do  a  NP_SIMPLE  's  ROLE_SIMPLE  ,  ROLE_SIMPLE  ,  and ROLE_SIMPLE\n",
      "\n",
      "               ROOT                                                           \n",
      "                |                                                              \n",
      "                S                                                             \n",
      "                |                                                              \n",
      "                VP                                                            \n",
      "  ______________|____________________                                          \n",
      " |                                  SBAR                                      \n",
      " |                                   |                                         \n",
      " |                                   S                                        \n",
      " |                        ___________|___________________________              \n",
      " |                       NP                                      |            \n",
      " |               ________|____________________                   |             \n",
      " |              NP                   |        |                  VP           \n",
      " |           ___|________________    |        |        __________|___          \n",
      " |          NP           |       |   |        |       |              NP       \n",
      " |     _____|___         |       |   |        |       |     _________|____     \n",
      "VBD   NN       POS       NN     POS  JJ       NN     VBP   NN        CC   NN  \n",
      " |    |         |        |       |   |        |       |    |         |    |    \n",
      "Did entity      's  ROLE_SIMPLE  's good ROLE_SIMPLE  do entity     and entity\n",
      "\n",
      "                ROOT                                                         \n",
      "                 |                                                            \n",
      "                 S                                                           \n",
      "                 |                                                            \n",
      "                 VP                                                          \n",
      "  _______________|_____________________                                       \n",
      " |                                    SBAR                                   \n",
      " |                                     |                                      \n",
      " |                                     S                                     \n",
      " |                           __________|________________________              \n",
      " |                          |                                   VP           \n",
      " |                          |                                ___|________     \n",
      " |                          NP                              |   |   |    NP  \n",
      " |     _____________________|_________________________      |   |   |    |    \n",
      "VBD   NN    ,    NN    ,    NN    ,    NN    ,   CC   NN   VBP  CC VBP   NN  \n",
      " |    |     |    |     |    |     |    |     |   |    |     |   |   |    |    \n",
      "Did entity  ,  entity  ,  entity  ,  entity  ,  and entity  do and  do entity\n",
      "\n",
      "                       ROOT                                                                      \n",
      "                        |                                                                         \n",
      "                        S                                                                        \n",
      "                        |                                                                         \n",
      "                        VP                                                                       \n",
      "  ______________________|______________________                                                   \n",
      " |                                            SBAR                                               \n",
      " |                                             |                                                  \n",
      " |                                             S                                                 \n",
      " |               ______________________________|_________                                         \n",
      " |              |                                        VP                                      \n",
      " |              |                    ____________________|_________                               \n",
      " |              |                   |          |                   VP                            \n",
      " |              |                   |          |     ______________|_______                       \n",
      " |              NP                  VP         |    |                      NP                    \n",
      " |           ___|_______         ___|____      |    |           ___________|_______________       \n",
      " |          NP          |       |        NP    |    |          NP          |       |       |     \n",
      " |     _____|___        |       |        |     |    |     _____|___        |       |       |      \n",
      "VBD   NN       POS      NN     VBP       NN    CC  VBP   NN       POS      NN      CC      NN    \n",
      " |    |         |       |       |        |     |    |    |         |       |       |       |      \n",
      "Did entity      's ROLE_SIMPLE  do     entity and   do entity      's ROLE_SIMPLE and ROLE_SIMPLE\n",
      "\n",
      "                                                  ROOT                                            \n",
      "                                                   |                                               \n",
      "                                                   SQ                                             \n",
      "  _________________________________________________|_______                                        \n",
      " |    |                                                    VP                                     \n",
      " |    |                     _______________________________|________                               \n",
      " |    |                    VP                              |        |                             \n",
      " |    |      ______________|_______                        |        |                              \n",
      " |    |     |                      NP                      |        |                             \n",
      " |    |     |               _______|_______________        |        |                              \n",
      " |    |     |              NP                      |       |        VP                            \n",
      " |    |     |           ___|_______________        |       |    ____|__________                    \n",
      " |    NP    |          NP          |       |       |       |   |               NP                 \n",
      " |    |     |     _____|___        |       |       |       |   |     __________|______________     \n",
      "VBD   NN   VBP   NN       POS      NN     POS      NN      CC VBP   NN    ,    NN    ,   CC   NN  \n",
      " |    |     |    |         |       |       |       |       |   |    |     |    |     |   |    |    \n",
      "Did entity  do entity      's ROLE_SIMPLE  's ROLE_SIMPLE and  do entity  ,  entity  ,  and entity\n",
      "\n",
      "           ROOT                                                                                          \n",
      "            |                                                                                             \n",
      "            SQ                                                                                           \n",
      "  __________|__________________________                                                                   \n",
      " |          |                          VP                                                                \n",
      " |          |            ______________|_______________________                                           \n",
      " |          |           |                                      NP                                        \n",
      " |          |           |                       _______________|___________________________________       \n",
      " |          |           |                      NP                      |       |       |   |       |     \n",
      " |          |           |               _______|_______________        |       |       |   |       |      \n",
      " |          |           |              NP                      |       |       |       |   |       |     \n",
      " |          |           |           ___|_______________        |       |       |       |   |       |      \n",
      " |          NP          |          NP          |       |       |       |       NP      |   |       NP    \n",
      " |     _____|_____      |     _____|___        |       |       |       |       |       |   |       |      \n",
      "VBD   NN    CC    NN   VBP   NN       POS      NN     POS      NN      ,       NN      ,   CC      NN    \n",
      " |    |     |     |     |    |         |       |       |       |       |       |       |   |       |      \n",
      "Did entity and  entity  do entity      's ROLE_SIMPLE  's ROLE_SIMPLE  ,  ROLE_SIMPLE  ,  and ROLE_SIMPLE\n",
      "\n",
      "                                         ROOT                                                \n",
      "                                          |                                                   \n",
      "                                          SQ                                                 \n",
      "  ________________________________________|_______________                                    \n",
      " |          |                                             VP                                 \n",
      " |          |               ______________________________|__________________                 \n",
      " |          |              VP         |        VP                |   |       VP              \n",
      " |          |           ___|____      |    ____|___              |   |    ___|___             \n",
      " |          NP         |        NP    |   |        NP            |   |   |       NP          \n",
      " |     _____|____      |        |     |   |     ___|______       |   |   |    ___|______      \n",
      "VBD   NN    CC   NN   VBP       NN    ,  VBP   DT         NN     ,   CC VBP  DT         NN   \n",
      " |    |     |    |     |        |     |   |    |          |      |   |   |   |          |     \n",
      "Did entity and entity  do     entity  ,   do   a      NP_SIMPLE  ,  and  do  a      NP_SIMPLE\n",
      "\n",
      "           ROOT                                                                                         \n",
      "            |                                                                                            \n",
      "            SQ                                                                                          \n",
      "  __________|____________________                                                                        \n",
      " |    |                          VP                                                                     \n",
      " |    |                  ________|_____________                                                          \n",
      " |    |                 |              |       VP                                                       \n",
      " |    |                 |              |    ___|__________                                               \n",
      " |    |                 |              |   |             SBAR                                           \n",
      " |    |                 |              |   |              |                                              \n",
      " |    |                 |              |   |              S                                             \n",
      " |    |                 |              |   |        ______|__________                                    \n",
      " |    |                 |              |   |       |                 VP                                 \n",
      " |    |                 |              |   |       |              ___|____                               \n",
      " |    |                 VP             |   |       |             |        PP                            \n",
      " |    |      ___________|___           |   |       |             |    ____|__________                    \n",
      " |    NP    |               NP         |   |       NP            |   |               NP                 \n",
      " |    |     |      _________|____      |   |    ___|______       |   |     __________|______________     \n",
      "VBD   NN   VBP    NN        CC   NN    CC VBP  DT         NN    VBP  IN   NN    ,    NN    ,   CC   NN  \n",
      " |    |     |     |         |    |     |   |   |          |      |   |    |     |    |     |   |    |    \n",
      "Did entity  do  entity     and entity and  do  a      NP_SIMPLE  do  by entity  ,  entity  ,  and entity\n",
      "\n",
      "                                                                                   ROOT                                                                    \n",
      "                                                                                    |                                                                       \n",
      "                                                                                    S                                                                      \n",
      "                                                                                    |                                                                       \n",
      "                                                                                    VP                                                                     \n",
      "  __________________________________________________________________________________|________                                                               \n",
      " |                                                                                          SBAR                                                           \n",
      " |                                                                                           |                                                              \n",
      " |                                                                                           S                                                             \n",
      " |                                               ____________________________________________|_______________________________                               \n",
      " |                                              NP                                                                           VP                            \n",
      " |           ___________________________________|_______                                              _______________________|_____                         \n",
      " |          NP                                         NML                                           |   |   |                     NP                      \n",
      " |     _____|___         _______________________________|____________________________________        |   |   |     ________________|___________________     \n",
      "VBD   NN       POS      NN      ,       NN      ,       NN      ,       NN      ,   CC       NN     VBP  CC VBP   NN    ,    NN    ,    NN    ,   CC   NN  \n",
      " |    |         |       |       |       |       |       |       |       |       |   |        |       |   |   |    |     |    |     |    |     |   |    |    \n",
      "Did entity      's ROLE_SIMPLE  ,  ROLE_SIMPLE  ,  ROLE_SIMPLE  ,  ROLE_SIMPLE  ,  and  ROLE_SIMPLE  do and  do entity  ,  entity  ,  entity  ,  and entity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree in trees.take(10):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase(q):\n",
    "    for k, v in {\n",
    "        '[ADJECTIVE_SIMPLE]' : 'big',\n",
    "        '[entity]' : 'something',\n",
    "        '[NP_SIMPLE]' : 'something',\n",
    "        '[ROLE_SIMPLE]' : 'something',\n",
    "        '[VP_SIMPLE]' : 'do',\n",
    "    }.items():\n",
    "        q = q.replace(k, v)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ROOT                                                                        \n",
      "                     |                                                                           \n",
      "                    FRAG                                                                        \n",
      "                     |                                                                           \n",
      "                    SBAR                                                                        \n",
      "  ___________________|______________________                                                     \n",
      " |                                          S                                                   \n",
      " |               ___________________________|____________________________                        \n",
      " |              NP                                                       |                      \n",
      " |        ______|________________                                        |                       \n",
      " |       |                      SBAR                                     |                      \n",
      " |       |       ________________|______                                 |                       \n",
      " |       |      |                       S                                |                      \n",
      " |       |      |                       |                                |                       \n",
      " |       |      |                       VP                               VP                     \n",
      " |       |      |          _____________|_______               __________|______                 \n",
      " |       |      |         VP            |       VP            |                 NP              \n",
      " |       |      |     ____|______       |    ___|______       |           ______|__________      \n",
      "WHNP     NP    WHNP  |           NP     |   |          NP     |          NP                |    \n",
      " |       |      |    |           |      |   |          |      |    ______|__________       |     \n",
      "WDT      NN    WDT  VBP          NN     CC  VB         NN    VBD  DT     NN        POS     NN   \n",
      " |       |      |    |           |      |   |          |      |   |      |          |      |     \n",
      "What something that  do      something and  do     something was  a  something      's something\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"What [NP_SIMPLE] that [VP_SIMPLE] [entity] and [VP_SIMPLE] [entity] was a [NP_SIMPLE] 's [ROLE_SIMPLE]\"\n",
    "t = next(parser.raw_parse(rephrase(q)))\n",
    "t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ROOT                               \n",
      "                            |                                  \n",
      "                            S                                 \n",
      "                            |                                  \n",
      "                            VP                                \n",
      "                 ___________|_____________________             \n",
      "                VP                    |           |           \n",
      "  ______________|____                 |           |            \n",
      " |                   NP               |           VP          \n",
      " |           ________|___________     |      _____|___         \n",
      " |          NP       |      |    |    |     |         NP      \n",
      " |     _____|___     |      |    |    |     |      ___|____    \n",
      "VBD  NNP       POS   JJ     NN   NN   CC    VB    NN       NN \n",
      " |    |         |    |      |    |    |     |     |        |   \n",
      "Did Jackie      's female actor edit and produce Rad     Plaid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = corenlp.CoreNLPParser()\n",
    "for tree in parser.raw_parse(df.rdd.map(lambda r: r['question']).take(1)[0]):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 64 in stage 20.0 failed 1 times, most recent failure: Lost task 64.0 in stage 20.0 (TID 1101, havoc.millennium.berkeley.edu, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 595, in process\n    out_iter = func(split_index, iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 425, in func\n    return f(iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1946, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    for k, v in iterator:\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-148-cc1d639480a6>\", line 1, in <lambda>\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 227, in raw_parse\n    return next(\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 284, in raw_parse_sents\n    parsed_data = self.api_call(\"\\n\".join(sentences), properties=default_properties)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 250, in api_call\n    response.raise_for_status()\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1248/1902692177.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7038/741820415.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7036/387365502.apply(Unknown Source)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDD$$Lambda$975/1980233534.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 595, in process\n    out_iter = func(split_index, iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 425, in func\n    return f(iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1946, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    for k, v in iterator:\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-148-cc1d639480a6>\", line 1, in <lambda>\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 227, in raw_parse\n    return next(\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 284, in raw_parse_sents\n    parsed_data = self.api_call(\"\\n\".join(sentences), properties=default_properties)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 250, in api_call\n    response.raise_for_status()\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1248/1902692177.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-cc1d639480a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 64 in stage 20.0 failed 1 times, most recent failure: Lost task 64.0 in stage 20.0 (TID 1101, havoc.millennium.berkeley.edu, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 595, in process\n    out_iter = func(split_index, iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 425, in func\n    return f(iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1946, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    for k, v in iterator:\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-148-cc1d639480a6>\", line 1, in <lambda>\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 227, in raw_parse\n    return next(\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 284, in raw_parse_sents\n    parsed_data = self.api_call(\"\\n\".join(sentences), properties=default_properties)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 250, in api_call\n    response.raise_for_status()\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1248/1902692177.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7038/741820415.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7036/387365502.apply(Unknown Source)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDD$$Lambda$975/1980233534.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 595, in process\n    out_iter = func(split_index, iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 2596, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 425, in func\n    return f(iterator)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1946, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 238, in mergeValues\n    for k, v in iterator:\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-148-cc1d639480a6>\", line 1, in <lambda>\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 227, in raw_parse\n    return next(\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 284, in raw_parse_sents\n    parsed_data = self.api_call(\"\\n\".join(sentences), properties=default_properties)\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/nltk/parse/corenlp.py\", line 250, in api_call\n    response.raise_for_status()\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:9000/?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1248/1902692177.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.rdd.map(lambda r: len(list(parser.raw_parse(r['question'])))).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROOT    \n",
      "     |       \n",
      "     S      \n",
      "     |       \n",
      "     VP     \n",
      "  ___|____   \n",
      " VB  CC   VB\n",
      " |   |    |  \n",
      " do and   do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = corenlp.CoreNLPParser()\n",
    "q = \"do and do\"\n",
    "t = next(parser.raw_parse(rephrase(q)))\n",
    "t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> WHNP VP | 'Did' NP VP\n",
    "    CC -> 'and'\n",
    "    DT -> 'a' | 'an'\n",
    "    JJ -> 'ADJECTIVE_SIMPLE'\n",
    "    N -> 'NP_SIMPLE' | 'ROLE_SIMPLE'\n",
    "    NP -> 'entity' | DT N | DT JJ N | NP POS N\n",
    "    V -> 'VP_SIMPLE'\n",
    "    VP -> 'was' V PP | VP CC VP\n",
    "    WHNP -> 'Who' | 'What' N\n",
    "    POS -> \"'s\"\n",
    "    P -> 'by'\n",
    "    PP -> P NP\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(grammar)\n",
    "# parser = nltk.ShiftReduceParser(grammar)\n",
    "\n",
    "sent = \"What [NP_SIMPLE] was [VP_SIMPLE] by [entity] and was [VP_SIMPLE] by a [ADJECTIVE_SIMPLE] [NP_SIMPLE] 's [ROLE_SIMPLE]\".replace('[', '').replace(']', '')\n",
    "trees = list(parser.parse(sent.split(' ')))\n",
    "print(len(trees))\n",
    "trees[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What NP_SIMPLE was VP_SIMPLE by entity and was VP_SIMPLE by a ADJECTIVE_SIMPLE NP_SIMPLE 's ROLE_SIMPLE\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'NP_SIMPLE', \"'s\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:50% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:50% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S                                       \n",
      "  ___|______________                          \n",
      " |                  VP                       \n",
      " |         _________|__________               \n",
      " |        VP                   PP            \n",
      " |    ____|___              ___|___           \n",
      " |   |        NP           |       NP        \n",
      " |   |     ___|_____       |    ___|_____     \n",
      " NP  V   Det        N      P  Det        N   \n",
      " |   |    |         |      |   |         |    \n",
      " I  shot  an     elephant  in  my     pajamas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "tree = next(parser.parse(sent))\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'NP_SIMPLE' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(grammar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
