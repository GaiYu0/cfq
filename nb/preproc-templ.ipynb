{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import *\n",
    "import json\n",
    "from operator import *\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import matplotlib.pylab as pl\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complexityMeasures',\n",
       " 'expectedResponse',\n",
       " 'expectedResponseWithMids',\n",
       " 'index',\n",
       " 'question',\n",
       " 'questionPatternModEntities',\n",
       " 'questionTemplate',\n",
       " 'questionWithBrackets',\n",
       " 'questionWithMids',\n",
       " 'ruleIds',\n",
       " 'ruleTree',\n",
       " 'sparql',\n",
       " 'sparqlPattern',\n",
       " 'sparqlPatternModEntities']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = '/data/yu_gai/cfq'\n",
    "output_dir = '/work/yu_gai/cfq/data/cfq'\n",
    "\n",
    "df = sqlCtx.read.parquet(f'{input_dir}/dataset.parquet').sort('index').persist()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcd1 95743 11968 11968 239357\n",
      "mcd2 95743 11968 11968 239357\n",
      "mcd3 95743 11968 11968 239357\n",
      "query_complexity_split 100654 9512 9512 239357\n",
      "query_pattern_split 94600 12489 12589 239357\n",
      "question_complexity_split 98999 10339 10340 239357\n",
      "question_pattern_split 95654 12115 11909 239357\n",
      "random_split 95744 11967 11967 239357\n"
     ]
    }
   ],
   "source": [
    "splits = {}\n",
    "split_ids = !ls {input_dir}/splits | grep json\n",
    "for split_id in [s.replace('.json', '') for s in split_ids]:\n",
    "    split = splits[split_id] = json.load(open(f'{input_dir}/splits/{split_id}.json'))\n",
    "    np.savez(f'{output_dir}/splits/{split_id}', **{k : np.array(v) for k, v in split.items()})\n",
    "    print(split_id, len(split['trainIdxs']), len(split['devIdxs']), len(split['testIdxs']), df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = r\"(:?[a-zA-Z]+|M[0-9]|'s|,)\"\n",
    "p = re.compile(fr'(:?{w} )+{w}')\n",
    "df.rdd.map(lambda r: re.match(p, r['questionPatternModEntities']).string).zip(df.rdd.map(lambda r: r['questionPatternModEntities'])).map(lambda r: r[0] == r[1]).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(q):\n",
    "    for s in [\n",
    "        'art director',\n",
    "        'country of nationality',\n",
    "        'costume designer',\n",
    "        'executive producer',\n",
    "        'executive produce',\n",
    "        'executive produced',\n",
    "        'film director',\n",
    "        'film distributor',\n",
    "        'film editor',\n",
    "        'film producer',\n",
    "        'production company',\n",
    "    ]:\n",
    "        q = q.replace(s, s.replace(' ', ''))\n",
    "    return q\n",
    "\n",
    "df = df.withColumn('questionPatternModEntities', udf(replace, StringType())('questionPatternModEntities')).persist()\n",
    "df.rdd.map(lambda r: len(r['questionPatternModEntities'].split(' ')) == len(r['questionTemplate'].split(' '))).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = lambda i: (lambda x: x[i])\n",
    "k1 = lambda r: [r, 1]\n",
    "unique = lambda rdd: sorted(rdd.distinct().collect())\n",
    "count = lambda rdd: dict(rdd.map(k1).reduceByKey(add).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rel(line):\n",
    "    if 'FILTER' in line:\n",
    "        [[src, dst, *_]] = re.findall(r'^FILTER \\( ([^ ]+) != ([^ ]+) \\)( .)?$', line)\n",
    "        return src, '!=', dst\n",
    "    else:\n",
    "        [[src, typ, dst, *_]] = re.findall(r'^([^ ]+) ([^ ]+) ([^ ]+)( .)?$', line)\n",
    "        return src, typ, dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['?x0',\n",
       "  '?x1',\n",
       "  '?x2',\n",
       "  '?x3',\n",
       "  '?x4',\n",
       "  '?x5',\n",
       "  'M0',\n",
       "  'M1',\n",
       "  'M2',\n",
       "  'M3',\n",
       "  'M4',\n",
       "  'M5',\n",
       "  'M6',\n",
       "  'M7',\n",
       "  'M8',\n",
       "  'M9'],\n",
       " ['!=',\n",
       "  '^ns:people.person.gender',\n",
       "  '^ns:people.person.nationality',\n",
       "  'a',\n",
       "  'ns:business.employer.employees/ns:business.employment_tenure.person',\n",
       "  'ns:film.actor.film/ns:film.performance.character',\n",
       "  'ns:film.actor.film/ns:film.performance.film',\n",
       "  'ns:film.cinematographer.film',\n",
       "  'ns:film.director.film',\n",
       "  'ns:film.editor.film',\n",
       "  'ns:film.film.cinematography',\n",
       "  'ns:film.film.costume_design_by',\n",
       "  'ns:film.film.directed_by',\n",
       "  'ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor',\n",
       "  'ns:film.film.edited_by',\n",
       "  'ns:film.film.executive_produced_by',\n",
       "  'ns:film.film.film_art_direction_by',\n",
       "  'ns:film.film.prequel',\n",
       "  'ns:film.film.produced_by|ns:film.film.production_companies',\n",
       "  'ns:film.film.sequel',\n",
       "  'ns:film.film.starring/ns:film.performance.actor',\n",
       "  'ns:film.film.written_by',\n",
       "  'ns:film.film_art_director.films_art_directed',\n",
       "  'ns:film.film_costumer_designer.costume_design_for_film',\n",
       "  'ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film',\n",
       "  'ns:film.producer.films_executive_produced',\n",
       "  'ns:film.producer.film|ns:film.production_company.films',\n",
       "  'ns:film.writer.film',\n",
       "  'ns:influence.influence_node.influenced',\n",
       "  'ns:influence.influence_node.influenced_by',\n",
       "  'ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company',\n",
       "  'ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired',\n",
       "  'ns:organization.organization.founders',\n",
       "  'ns:organization.organization_founder.organizations_founded',\n",
       "  'ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child',\n",
       "  'ns:people.person.employment_history/ns:business.employment_tenure.company',\n",
       "  'ns:people.person.gender',\n",
       "  'ns:people.person.nationality',\n",
       "  'ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent',\n",
       "  'ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings',\n",
       "  'ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses'],\n",
       " ['?x0',\n",
       "  '?x1',\n",
       "  '?x2',\n",
       "  '?x3',\n",
       "  '?x4',\n",
       "  '?x5',\n",
       "  'M0',\n",
       "  'M1',\n",
       "  'M2',\n",
       "  'M3',\n",
       "  'M4',\n",
       "  'M5',\n",
       "  'M6',\n",
       "  'M7',\n",
       "  'M8',\n",
       "  'M9',\n",
       "  'ns:business.employer',\n",
       "  'ns:fictional_universe.fictional_character',\n",
       "  'ns:film.actor',\n",
       "  'ns:film.cinematographer',\n",
       "  'ns:film.director',\n",
       "  'ns:film.editor',\n",
       "  'ns:film.film',\n",
       "  'ns:film.film_art_director',\n",
       "  'ns:film.film_costumer_designer',\n",
       "  'ns:film.film_distributor',\n",
       "  'ns:film.producer',\n",
       "  'ns:film.production_company',\n",
       "  'ns:film.writer',\n",
       "  'ns:m.02zsn',\n",
       "  'ns:m.0345h',\n",
       "  'ns:m.03_3d',\n",
       "  'ns:m.03rjj',\n",
       "  'ns:m.059j2',\n",
       "  'ns:m.05zppz',\n",
       "  'ns:m.06mkj',\n",
       "  'ns:m.07ssc',\n",
       "  'ns:m.09c7w0',\n",
       "  'ns:m.0b90_r',\n",
       "  'ns:m.0d05w3',\n",
       "  'ns:m.0d060g',\n",
       "  'ns:m.0d0vqn',\n",
       "  'ns:m.0f8l9c',\n",
       "  'ns:people.person'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels = df.rdd.flatMap(lambda r: r['sparqlPatternModEntities'].split('\\n')[1 : -1]).map(find_rel).cache()\n",
    "srcs, typs, dsts = map(unique, [rels.map(at(0)), rels.map(at(1)), rels.map(at(2))])\n",
    "srcs, typs, dsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^ns:people.person.gender',\n",
       " '^ns:people.person.nationality',\n",
       " 'ns:business.employer.employees/ns:business.employment_tenure.person',\n",
       " 'ns:film.actor.film/ns:film.performance.character',\n",
       " 'ns:film.actor.film/ns:film.performance.film',\n",
       " 'ns:film.cinematographer.film',\n",
       " 'ns:film.director.film',\n",
       " 'ns:film.editor.film',\n",
       " 'ns:film.film.cinematography',\n",
       " 'ns:film.film.costume_design_by',\n",
       " 'ns:film.film.directed_by',\n",
       " 'ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor',\n",
       " 'ns:film.film.edited_by',\n",
       " 'ns:film.film.executive_produced_by',\n",
       " 'ns:film.film.film_art_direction_by',\n",
       " 'ns:film.film.prequel',\n",
       " 'ns:film.film.produced_by|ns:film.film.production_companies',\n",
       " 'ns:film.film.sequel',\n",
       " 'ns:film.film.starring/ns:film.performance.actor',\n",
       " 'ns:film.film.written_by',\n",
       " 'ns:film.film_art_director.films_art_directed',\n",
       " 'ns:film.film_costumer_designer.costume_design_for_film',\n",
       " 'ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film',\n",
       " 'ns:film.producer.films_executive_produced',\n",
       " 'ns:film.producer.film|ns:film.production_company.films',\n",
       " 'ns:film.writer.film',\n",
       " 'ns:influence.influence_node.influenced',\n",
       " 'ns:influence.influence_node.influenced_by',\n",
       " 'ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company',\n",
       " 'ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired',\n",
       " 'ns:organization.organization.founders',\n",
       " 'ns:organization.organization_founder.organizations_founded',\n",
       " 'ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child',\n",
       " 'ns:people.person.employment_history/ns:business.employment_tenure.company',\n",
       " 'ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent',\n",
       " 'ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings',\n",
       " 'ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2typ = sorted(typ for typ in typs if typ not in ['a', '!=', 'ns:people.person.gender', 'ns:people.person.nationality'])\n",
    "typ2idx = {typ : idx for idx, typ in enumerate(idx2typ)}\n",
    "idx2typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Did M2 , M3 , M4 , and M5 found a productioncompany that was acquired by M1',\n",
       " 'Did M2 employ M3 and M4 and employ a filmproducer whose employer was acquired by M1',\n",
       " 'Did M2 acquire M3 , acquire a productioncompany that M1 acquired , and acquire M4 , M5 , and M6',\n",
       " 'Did M4 acquire a filmdistributor that M1 , M2 , and M3 acquired',\n",
       " 'Did M2 acquire a filmdistributor that M1 acquired and acquire M3',\n",
       " 'Did M6 acquire a filmdistributor that M1 , M2 , M3 , M4 , and M5 acquired and acquire M7',\n",
       " 'Did M3 and M4 found a filmdistributor that M1 and M2 acquired',\n",
       " 'Did M4 found a company that M1 , M2 , and M3 acquired',\n",
       " 'Did M3 found a company acquired by M1 and M2',\n",
       " 'Did M3 found M4 and found a filmdistributor that acquired M2 and was acquired by M1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquiring = 'ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company'\n",
    "df.rdd.filter(lambda r: acquiring in r['sparqlPatternModEntities']).map(lambda r: r['questionPatternModEntities']).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.production_company .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "M2 ns:organization.organization_founder.organizations_founded ?x0 .\n",
      "M3 ns:organization.organization_founder.organizations_founded ?x0 .\n",
      "M4 ns:organization.organization_founder.organizations_founded ?x0 .\n",
      "M5 ns:organization.organization_founder.organizations_founded ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.producer .\n",
      "?x0 ns:people.person.employment_history/ns:business.employment_tenure.company ?x1 .\n",
      "?x1 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0 .\n",
      "M2 ns:business.employer.employees/ns:business.employment_tenure.person M3 .\n",
      "M2 ns:business.employer.employees/ns:business.employment_tenure.person M4\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.production_company .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M3 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M4 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M5 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M6\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.film_distributor .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M2 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M3 .\n",
      "M4 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.film_distributor .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M3\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.film_distributor .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M2 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M3 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M4 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M5 .\n",
      "M6 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0 .\n",
      "M6 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M7\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.film_distributor .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M2 .\n",
      "M3 ns:organization.organization_founder.organizations_founded ?x0 .\n",
      "M4 ns:organization.organization_founder.organizations_founded ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:business.employer .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M2 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M3 .\n",
      "M4 ns:organization.organization_founder.organizations_founded ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:business.employer .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M2 .\n",
      "M3 ns:organization.organization_founder.organizations_founded ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.film_distributor .\n",
      "?x0 ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company M1 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M2 .\n",
      "M3 ns:organization.organization_founder.organizations_founded ?x0 .\n",
      "M3 ns:organization.organization_founder.organizations_founded M4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for sparql in df.rdd.filter(lambda r: acquiring in r['sparqlPatternModEntities']).map(lambda r: r['sparqlPatternModEntities']).take(10):\n",
    "    print(sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Did M0 's child 's child acquire a filmdistributor\",\n",
       " \"Did M6 's distributor and producer acquire M0 and acquire M1 , M2 , M3 , M4 , and M5\",\n",
       " \"Did M2 's producer acquire M0 and M1 and acquire a productioncompany\",\n",
       " 'Did M0 acquire M1 and M2 , acquire M3 , and acquire M4 , M5 , M6 , and M7',\n",
       " \"Did M1 acquire M2 , M3 , and M4 and acquire a filmdirector 's employer\",\n",
       " \"Did M2 acquire a company and acquire M0 's employer\",\n",
       " \"Did M1 acquire M0 's distributor\",\n",
       " \"Did M1 acquire M0 's producer\",\n",
       " 'Did M1 acquire a producer of M0',\n",
       " 'Did M1 acquire a producer of a film']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquired = 'ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired'\n",
    "df.rdd.filter(lambda r: acquired in r['sparqlPatternModEntities']).map(lambda r: r['questionPatternModEntities']).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) WHERE {\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x1 .\n",
      "?x0 ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent ?x2 .\n",
      "?x1 a ns:film.film_distributor .\n",
      "?x2 ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent M0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film M6 .\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films M6 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M0 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M1 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M2 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M3 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M4 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M5\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films M2 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x1 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M0 .\n",
      "?x0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M1 .\n",
      "?x1 a ns:film.production_company\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M1 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M2 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M3 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M4 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M5 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M6 .\n",
      "M0 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M7\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:business.employer.employees/ns:business.employment_tenure.person ?x1 .\n",
      "?x1 a ns:film.director .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M2 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M3 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired M4\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:business.employer.employees/ns:business.employment_tenure.person M0 .\n",
      "?x1 a ns:business.employer .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0 .\n",
      "M2 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x1\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film M0 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films M0 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films M0 .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0\n",
      "}\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films ?x1 .\n",
      "?x1 a ns:film.film .\n",
      "M1 ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired ?x0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for sparql in df.rdd.filter(lambda r: acquired in r['sparqlPatternModEntities']).map(lambda r: r['sparqlPatternModEntities']).take(10):\n",
    "    print(sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['?x0',\n",
       "  '?x1',\n",
       "  '?x2',\n",
       "  '?x3',\n",
       "  '?x4',\n",
       "  '?x5',\n",
       "  'M0',\n",
       "  'M1',\n",
       "  'M2',\n",
       "  'M3',\n",
       "  'M4',\n",
       "  'M5',\n",
       "  'M6'],\n",
       " ['ns:business.employer',\n",
       "  'ns:fictional_universe.fictional_character',\n",
       "  'ns:film.actor',\n",
       "  'ns:film.cinematographer',\n",
       "  'ns:film.director',\n",
       "  'ns:film.editor',\n",
       "  'ns:film.film',\n",
       "  'ns:film.film_art_director',\n",
       "  'ns:film.film_costumer_designer',\n",
       "  'ns:film.film_distributor',\n",
       "  'ns:film.producer',\n",
       "  'ns:film.production_company',\n",
       "  'ns:film.writer',\n",
       "  'ns:people.person'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categories\n",
    "a = rels.filter(lambda r: r[1] == 'a').cache()\n",
    "cats = unique(a.map(at(2)))\n",
    "unique(a.map(at(0))), cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns:m.02zsn ['ns:people.person.gender']\n",
      "ns:m.0345h ['ns:people.person.nationality']\n",
      "ns:m.03_3d ['ns:people.person.nationality']\n",
      "ns:m.03rjj ['ns:people.person.nationality']\n",
      "ns:m.059j2 ['ns:people.person.nationality']\n",
      "ns:m.05zppz ['ns:people.person.gender']\n",
      "ns:m.06mkj ['ns:people.person.nationality']\n",
      "ns:m.07ssc ['ns:people.person.nationality']\n",
      "ns:m.09c7w0 ['ns:people.person.nationality']\n",
      "ns:m.0b90_r ['ns:people.person.nationality']\n",
      "ns:m.0d05w3 ['ns:people.person.nationality']\n",
      "ns:m.0d060g ['ns:people.person.nationality']\n",
      "ns:m.0d0vqn ['ns:people.person.nationality']\n",
      "ns:m.0f8l9c ['ns:people.person.nationality']\n"
     ]
    }
   ],
   "source": [
    "# gender and nationality\n",
    "for dst in dsts:\n",
    "    if dst.startswith('ns:') and dst not in cats:\n",
    "        print(dst, unique(rels.filter(lambda r: r[2] == dst).map(at(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ns:business.employer',\n",
       " 'ns:fictional_universe.fictional_character',\n",
       " 'ns:film.actor',\n",
       " 'ns:film.cinematographer',\n",
       " 'ns:film.director',\n",
       " 'ns:film.editor',\n",
       " 'ns:film.film',\n",
       " 'ns:film.film_art_director',\n",
       " 'ns:film.film_costumer_designer',\n",
       " 'ns:film.film_distributor',\n",
       " 'ns:film.producer',\n",
       " 'ns:film.production_company',\n",
       " 'ns:film.writer',\n",
       " 'ns:m.02zsn',\n",
       " 'ns:m.0345h',\n",
       " 'ns:m.03_3d',\n",
       " 'ns:m.03rjj',\n",
       " 'ns:m.059j2',\n",
       " 'ns:m.05zppz',\n",
       " 'ns:m.06mkj',\n",
       " 'ns:m.07ssc',\n",
       " 'ns:m.09c7w0',\n",
       " 'ns:m.0b90_r',\n",
       " 'ns:m.0d05w3',\n",
       " 'ns:m.0d060g',\n",
       " 'ns:m.0d0vqn',\n",
       " 'ns:m.0f8l9c',\n",
       " 'ns:people.person']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2attr = sorted(dst for dst in dsts if dst.startswith('ns:'))\n",
    "idx2attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['?x0',\n",
       "  '?x1',\n",
       "  '?x2',\n",
       "  '?x3',\n",
       "  '?x4',\n",
       "  'M0',\n",
       "  'M1',\n",
       "  'M2',\n",
       "  'M3',\n",
       "  'M4',\n",
       "  'M5',\n",
       "  'M6',\n",
       "  'M7'],\n",
       " ['?x0',\n",
       "  '?x1',\n",
       "  '?x2',\n",
       "  '?x3',\n",
       "  '?x4',\n",
       "  '?x5',\n",
       "  'M0',\n",
       "  'M1',\n",
       "  'M2',\n",
       "  'M3',\n",
       "  'M4',\n",
       "  'M5',\n",
       "  'M6',\n",
       "  'M7',\n",
       "  'M8'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne = rels.filter(lambda r: r[1] == '!=').cache()\n",
    "unique(ne.map(at(0))), unique(ne.map(at(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " ',',\n",
       " 'American',\n",
       " 'British',\n",
       " 'Canadian',\n",
       " 'Chinese',\n",
       " 'Did',\n",
       " 'Dutch',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'Mexican',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Was',\n",
       " 'Were',\n",
       " 'What',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'a',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'artdirector',\n",
       " 'by',\n",
       " 'character',\n",
       " 'child',\n",
       " 'cinematographer',\n",
       " 'company',\n",
       " 'costumedesigner',\n",
       " 'countryofnationality',\n",
       " 'did',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'director',\n",
       " 'distribute',\n",
       " 'distributed',\n",
       " 'distributor',\n",
       " 'edit',\n",
       " 'edited',\n",
       " 'editor',\n",
       " 'employ',\n",
       " 'employed',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'executiveproduce',\n",
       " 'executiveproduced',\n",
       " 'executiveproducer',\n",
       " 'female',\n",
       " 'film',\n",
       " 'filmdirector',\n",
       " 'filmdistributor',\n",
       " 'filmeditor',\n",
       " 'filmproducer',\n",
       " 'found',\n",
       " 'founded',\n",
       " 'founder',\n",
       " 'gender',\n",
       " 'influence',\n",
       " 'influenced',\n",
       " 'male',\n",
       " 'married',\n",
       " 'marry',\n",
       " 'of',\n",
       " 'parent',\n",
       " 'person',\n",
       " 'play',\n",
       " 'played',\n",
       " 'prequel',\n",
       " 'produce',\n",
       " 'produced',\n",
       " 'producer',\n",
       " 'productioncompany',\n",
       " 'screenwriter',\n",
       " 'sequel',\n",
       " 'sibling',\n",
       " 'spouse',\n",
       " 'star',\n",
       " 'starred',\n",
       " 'that',\n",
       " 'was',\n",
       " 'were',\n",
       " 'whose',\n",
       " 'write',\n",
       " 'writer',\n",
       " 'written',\n",
       " 'wrote']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_vocab = unique(df.rdd.flatMap(lambda r: r['questionPatternModEntities'].split(' ')))\n",
    "tok_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M0 2 20\n",
      "M1 2 17\n",
      "M2 2 28\n",
      "M3 2 13\n",
      "M4 2 5\n",
      "M5 2 1\n",
      "mcd1\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "mcd2\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "mcd3\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "query_complexity_split\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "query_pattern_split\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "question_complexity_split\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "question_pattern_split\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n",
      "random_split\n",
      "M0 2 6\n",
      "M1 2 12\n",
      "M2 2 11\n",
      "M3 2 5\n",
      "M4 2 1\n"
     ]
    }
   ],
   "source": [
    "# repeated occurence of entities\n",
    "def _mapper(r):\n",
    "    c = defaultdict(lambda: 0)\n",
    "    for tok in r['questionPatternModEntities'].split(' '):\n",
    "        if re.match('M\\d', tok) is not None:\n",
    "            c[tok] += 1\n",
    "    return c.items()\n",
    "\n",
    "def _fn(rdd):\n",
    "    for [tok, c], n in sorted(count(rdd.flatMap(_mapper)).items()):\n",
    "        if c > 1:\n",
    "            print(tok, c, n)\n",
    "\n",
    "_fn(df.rdd)\n",
    "\n",
    "for k, v in splits.items():\n",
    "    print(k)\n",
    "    indices = set(chain(*splits['mcd1'].values()))\n",
    "    _fn(df.rdd.filter(lambda r: r['index'] in indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _mapper(r):\n",
    "    rels = list(map(find_rel, r['sparqlPatternModEntities'].split('\\n')[1 : -1]))\n",
    "    ends = set((src, dst) for src, typ, dst in rels if typ != '!=')\n",
    "    return all((src, dst) in ends for src, typ, dst in rels if typ == '!=')\n",
    "\n",
    "df.rdd.map(_mapper).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ns:film.film.costume_design_by', 56),\n",
       " ('ns:film.film.cinematography', 99),\n",
       " ('ns:film.film.film_art_direction_by', 101),\n",
       " ('^ns:people.person.gender', 1088),\n",
       " ('^ns:people.person.nationality', 2171),\n",
       " ('ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film',\n",
       "  5210),\n",
       " ('ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired',\n",
       "  5814),\n",
       " ('ns:film.film.prequel', 6337),\n",
       " ('ns:film.film.sequel', 6906),\n",
       " ('ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company',\n",
       "  7584),\n",
       " ('ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor',\n",
       "  9712),\n",
       " ('ns:film.film.starring/ns:film.performance.actor', 11668),\n",
       " ('ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent',\n",
       "  15451),\n",
       " ('ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child',\n",
       "  16142),\n",
       " ('ns:film.actor.film/ns:film.performance.character', 16942),\n",
       " ('ns:business.employer.employees/ns:business.employment_tenure.person',\n",
       "  19286),\n",
       " ('ns:film.film_costumer_designer.costume_design_for_film', 19961),\n",
       " ('ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings',\n",
       "  20668),\n",
       " ('ns:organization.organization.founders', 23239),\n",
       " ('ns:film.film_art_director.films_art_directed', 25045),\n",
       " ('ns:film.cinematographer.film', 30865),\n",
       " ('ns:people.person.gender', 31770),\n",
       " ('ns:influence.influence_node.influenced', 34149),\n",
       " ('ns:organization.organization_founder.organizations_founded', 36247),\n",
       " ('ns:film.actor.film/ns:film.performance.film', 37356),\n",
       " ('ns:people.person.employment_history/ns:business.employment_tenure.company',\n",
       "  42710),\n",
       " ('ns:film.producer.films_executive_produced', 48110),\n",
       " ('ns:film.producer.film|ns:film.production_company.films', 48275),\n",
       " ('ns:film.film.produced_by|ns:film.film.production_companies', 50440),\n",
       " ('ns:film.film.edited_by', 57106),\n",
       " ('ns:film.film.executive_produced_by', 57805),\n",
       " ('ns:film.film.directed_by', 57981),\n",
       " ('ns:film.film.written_by', 59613),\n",
       " ('ns:film.writer.film', 60544),\n",
       " ('ns:film.director.film', 60617),\n",
       " ('ns:film.editor.film', 60634),\n",
       " ('ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses',\n",
       "  61439),\n",
       " ('ns:influence.influence_node.influenced_by', 64052),\n",
       " ('ns:people.person.nationality', 71306),\n",
       " ('!=', 82107),\n",
       " ('a', 170287)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rels.map(at(1)).map(k1).reduceByKey(add).collect(), key=at(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'ns:business.employer',\n",
       " 'ns:fictional_universe.fictional_character',\n",
       " 'ns:film.actor',\n",
       " 'ns:film.cinematographer',\n",
       " 'ns:film.director',\n",
       " 'ns:film.editor',\n",
       " 'ns:film.film',\n",
       " 'ns:film.film_art_director',\n",
       " 'ns:film.film_costumer_designer',\n",
       " 'ns:film.film_distributor',\n",
       " 'ns:film.producer',\n",
       " 'ns:film.production_company',\n",
       " 'ns:film.writer',\n",
       " 'ns:m.02zsn',\n",
       " 'ns:m.0345h',\n",
       " 'ns:m.03_3d',\n",
       " 'ns:m.03rjj',\n",
       " 'ns:m.059j2',\n",
       " 'ns:m.05zppz',\n",
       " 'ns:m.06mkj',\n",
       " 'ns:m.07ssc',\n",
       " 'ns:m.09c7w0',\n",
       " 'ns:m.0b90_r',\n",
       " 'ns:m.0d05w3',\n",
       " 'ns:m.0d060g',\n",
       " 'ns:m.0d0vqn',\n",
       " 'ns:m.0f8l9c',\n",
       " 'ns:people.person']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[NP_SIMPLE]',\n",
       " '[entity]',\n",
       " '[ADJECTIVE_SIMPLE]',\n",
       " '[VP_SIMPLE]',\n",
       " '[ROLE_SIMPLE]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roles = df.rdd.flatMap(lambda r: re.findall(r'\\[[^\\]]+\\]', r['questionTemplate'])).distinct().collect()\n",
    "roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[NP_SIMPLE]': {'actor',\n",
       "  'artdirector',\n",
       "  'character',\n",
       "  'cinematographer',\n",
       "  'company',\n",
       "  'costumedesigner',\n",
       "  'film',\n",
       "  'filmdirector',\n",
       "  'filmdistributor',\n",
       "  'filmeditor',\n",
       "  'filmproducer',\n",
       "  'person',\n",
       "  'productioncompany',\n",
       "  'screenwriter'},\n",
       " '[entity]': {'M0', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9'},\n",
       " '[ADJECTIVE_SIMPLE]': {'American',\n",
       "  'British',\n",
       "  'Canadian',\n",
       "  'Chinese',\n",
       "  'Dutch',\n",
       "  'French',\n",
       "  'German',\n",
       "  'Italian',\n",
       "  'Japanese',\n",
       "  'Mexican',\n",
       "  'Spanish',\n",
       "  'Swedish',\n",
       "  'female',\n",
       "  'male'},\n",
       " '[VP_SIMPLE]': {'acquire',\n",
       "  'acquired',\n",
       "  'direct',\n",
       "  'directed',\n",
       "  'distribute',\n",
       "  'distributed',\n",
       "  'edit',\n",
       "  'edited',\n",
       "  'employ',\n",
       "  'employed',\n",
       "  'executiveproduce',\n",
       "  'executiveproduced',\n",
       "  'found',\n",
       "  'founded',\n",
       "  'influence',\n",
       "  'influenced',\n",
       "  'married',\n",
       "  'marry',\n",
       "  'play',\n",
       "  'played',\n",
       "  'produce',\n",
       "  'produced',\n",
       "  'star',\n",
       "  'starred',\n",
       "  'write',\n",
       "  'written',\n",
       "  'wrote'},\n",
       " '[ROLE_SIMPLE]': {'actor',\n",
       "  'artdirector',\n",
       "  'child',\n",
       "  'cinematographer',\n",
       "  'costumedesigner',\n",
       "  'countryofnationality',\n",
       "  'director',\n",
       "  'distributor',\n",
       "  'editor',\n",
       "  'employee',\n",
       "  'employer',\n",
       "  'executiveproducer',\n",
       "  'founder',\n",
       "  'gender',\n",
       "  'parent',\n",
       "  'prequel',\n",
       "  'producer',\n",
       "  'sequel',\n",
       "  'sibling',\n",
       "  'spouse',\n",
       "  'star',\n",
       "  'writer'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _mapper(r):\n",
    "    d = defaultdict(set)\n",
    "    for x, y in zip(r['questionPatternModEntities'].split(' '), r['questionTemplate'].split(' ')):\n",
    "        if y in roles:\n",
    "            d[y].add(x)\n",
    "    return [[role, d[role]] for role in roles]\n",
    "\n",
    "role2toks = dict(df.rdd.flatMap(_mapper).reduceByKey(set.union).collect())\n",
    "role2toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_roles = ['[VP_SIMPLE]', '[ROLE_SIMPLE]']\n",
    "\n",
    "def _mapper(r):\n",
    "    uniq_toks = set()\n",
    "    for role in special_roles:\n",
    "        for tok in role2toks[role]:\n",
    "            if tok in r['questionPatternModEntities'].split(' '):\n",
    "                uniq_toks.add(tok)\n",
    "    _, typs, _ = list(zip(*map(find_rel, r['sparqlPatternModEntities'].split('\\n')[1 : -1])))\n",
    "    uniq_typs = set(typs)\n",
    "    return list(product(uniq_toks, uniq_typs)), uniq_toks, uniq_typs\n",
    "\n",
    "occs = df.rdd.map(_mapper).persist()\n",
    "both, c_tok, c_rel = map(count, (occs.flatMap(at(0)), occs.flatMap(at(1)), occs.flatMap(at(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquire 1830\n",
      "['ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired', 1307]\n",
      "['a', 1086]\n",
      "['ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company', 540]\n",
      "acquired 2625\n",
      "['ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company', 2246]\n",
      "['a', 1826]\n",
      "['ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired', 809]\n",
      "actor 20287\n",
      "['a', 15062]\n",
      "['ns:film.actor.film/ns:film.performance.character', 9219]\n",
      "['ns:people.person.nationality', 7425]\n",
      "artdirector 31822\n",
      "['ns:film.film_art_director.films_art_directed', 22744]\n",
      "['a', 17117]\n",
      "['ns:film.editor.film', 9740]\n",
      "child 14955\n",
      "['ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent', 14747]\n",
      "['a', 9731]\n",
      "['ns:people.person.nationality', 4293]\n",
      "cinematographer 37256\n",
      "['ns:film.cinematographer.film', 26135]\n",
      "['a', 20010]\n",
      "['ns:film.editor.film', 11418]\n",
      "costumedesigner 27051\n",
      "['ns:film.film_costumer_designer.costume_design_for_film', 18185]\n",
      "['a', 15730]\n",
      "['ns:film.editor.film', 7366]\n",
      "countryofnationality 2091\n",
      "['^ns:people.person.nationality', 2034]\n",
      "['a', 1070]\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 664]\n",
      "direct 12994\n",
      "['ns:film.director.film', 9553]\n",
      "['ns:film.editor.film', 6122]\n",
      "['ns:film.writer.film', 5917]\n",
      "directed 35325\n",
      "['ns:film.film.directed_by', 27909]\n",
      "['a', 19373]\n",
      "['ns:film.film.edited_by', 15800]\n",
      "director 27032\n",
      "['ns:film.director.film', 26945]\n",
      "['ns:film.editor.film', 10073]\n",
      "['ns:film.writer.film', 9855]\n",
      "distribute 1357\n",
      "['a', 802]\n",
      "['ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor', 742]\n",
      "['ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film', 642]\n",
      "distributed 4012\n",
      "['ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor', 3455]\n",
      "['a', 2725]\n",
      "['ns:film.film.produced_by|ns:film.film.production_companies', 2436]\n",
      "distributor 2936\n",
      "['ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film', 2921]\n",
      "['a', 1334]\n",
      "['ns:film.producer.film|ns:film.production_company.films', 1236]\n",
      "edit 13465\n",
      "['ns:film.editor.film', 9889]\n",
      "['ns:film.director.film', 6136]\n",
      "['ns:film.writer.film', 6118]\n",
      "edited 35069\n",
      "['ns:film.film.edited_by', 27680]\n",
      "['a', 19194]\n",
      "['ns:film.film.directed_by', 15802]\n",
      "editor 26676\n",
      "['ns:film.editor.film', 26590]\n",
      "['ns:film.director.film', 10025]\n",
      "['ns:film.writer.film', 9765]\n",
      "employ 4485\n",
      "['ns:business.employer.employees/ns:business.employment_tenure.person', 3211]\n",
      "['a', 3031]\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 1639]\n",
      "employed 10157\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 9027]\n",
      "['a', 8270]\n",
      "['ns:organization.organization_founder.organizations_founded', 3379]\n",
      "employee 14665\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 14106]\n",
      "['a', 8386]\n",
      "['ns:organization.organization_founder.organizations_founded', 6644]\n",
      "employer 6398\n",
      "['ns:business.employer.employees/ns:business.employment_tenure.person', 6161]\n",
      "['a', 4194]\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 1923]\n",
      "executiveproduce 12932\n",
      "['ns:film.producer.films_executive_produced', 8590]\n",
      "['ns:film.director.film', 5397]\n",
      "['ns:film.writer.film', 5318]\n",
      "executiveproduced 33610\n",
      "['ns:film.film.executive_produced_by', 27274]\n",
      "['a', 18347]\n",
      "['ns:film.film.written_by', 14632]\n",
      "executiveproducer 21191\n",
      "['ns:film.producer.films_executive_produced', 21129]\n",
      "['a', 8169]\n",
      "['ns:film.writer.film', 7444]\n",
      "found 4168\n",
      "['ns:organization.organization_founder.organizations_founded', 2497]\n",
      "['a', 2426]\n",
      "['ns:organization.organization.founders', 1808]\n",
      "founded 11375\n",
      "['a', 8246]\n",
      "['ns:organization.organization.founders', 6556]\n",
      "['ns:organization.organization_founder.organizations_founded', 5550]\n",
      "founder 15611\n",
      "['ns:organization.organization_founder.organizations_founded', 15014]\n",
      "['a', 8960]\n",
      "['ns:people.person.employment_history/ns:business.employment_tenure.company', 6701]\n",
      "gender 1024\n",
      "['^ns:people.person.gender', 1024]\n",
      "['ns:people.person.nationality', 584]\n",
      "['a', 478]\n",
      "influence 12828\n",
      "['a', 8589]\n",
      "['ns:influence.influence_node.influenced', 7951]\n",
      "['!=', 7403]\n",
      "influenced 25279\n",
      "['a', 20979]\n",
      "['ns:influence.influence_node.influenced_by', 20798]\n",
      "['ns:influence.influence_node.influenced', 9555]\n",
      "married 10186\n",
      "['!=', 10186]\n",
      "['ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses', 10186]\n",
      "['a', 9239]\n",
      "marry 13456\n",
      "['ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses', 13456]\n",
      "['!=', 13456]\n",
      "['a', 9204]\n",
      "parent 15574\n",
      "['ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child', 15374]\n",
      "['a', 10295]\n",
      "['ns:people.person.nationality', 4486]\n",
      "play 1235\n",
      "['ns:film.actor.film/ns:film.performance.character', 1235]\n",
      "['ns:people.person.nationality', 481]\n",
      "['a', 416]\n",
      "played 2093\n",
      "['ns:film.actor.film/ns:film.performance.character', 2093]\n",
      "['a', 1570]\n",
      "['ns:people.person.nationality', 926]\n",
      "prequel 6682\n",
      "['ns:film.film.sequel', 6638]\n",
      "['a', 2832]\n",
      "['ns:film.director.film', 1707]\n",
      "produce 12330\n",
      "['ns:film.producer.film|ns:film.production_company.films', 8582]\n",
      "['ns:film.editor.film', 5459]\n",
      "['ns:film.director.film', 5410]\n",
      "produced 31964\n",
      "['ns:film.film.produced_by|ns:film.film.production_companies', 26718]\n",
      "['a', 17228]\n",
      "['ns:film.film.written_by', 13755]\n",
      "producer 25660\n",
      "['ns:film.producer.film|ns:film.production_company.films', 25645]\n",
      "['a', 9777]\n",
      "['ns:film.editor.film', 8536]\n",
      "sequel 6173\n",
      "['ns:film.film.prequel', 6129]\n",
      "['a', 2811]\n",
      "['ns:film.director.film', 1557]\n",
      "sibling 19568\n",
      "['!=', 19568]\n",
      "['ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings', 19568]\n",
      "['a', 11609]\n",
      "spouse 20224\n",
      "['ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses', 20224]\n",
      "['!=', 20224]\n",
      "['a', 11993]\n",
      "star 30774\n",
      "['ns:film.actor.film/ns:film.performance.film', 27305]\n",
      "['a', 12937]\n",
      "['ns:film.director.film', 9348]\n",
      "starred 3355\n",
      "['a', 3088]\n",
      "['ns:film.actor.film/ns:film.performance.film', 2471]\n",
      "['ns:people.person.nationality', 1171]\n",
      "write 13169\n",
      "['ns:film.writer.film', 9484]\n",
      "['ns:film.editor.film', 6070]\n",
      "['ns:film.director.film', 5946]\n",
      "writer 26892\n",
      "['ns:film.writer.film', 26799]\n",
      "['a', 10145]\n",
      "['ns:film.editor.film', 9819]\n",
      "written 30157\n",
      "['ns:film.film.written_by', 27840]\n",
      "['a', 15617]\n",
      "['ns:film.film.edited_by', 15430]\n",
      "wrote 5048\n",
      "['ns:film.writer.film', 4959]\n",
      "['a', 3898]\n",
      "['ns:film.director.film', 2146]\n",
      "\n",
      "!= 56702\n",
      "['spouse', 20224]\n",
      "['sibling', 19568]\n",
      "['marry', 13456]\n",
      "^ns:people.person.gender 1024\n",
      "['gender', 1024]\n",
      "['actor', 135]\n",
      "['sibling', 134]\n",
      "^ns:people.person.nationality 2034\n",
      "['countryofnationality', 2034]\n",
      "['employed', 339]\n",
      "['employee', 286]\n",
      "a 146641\n",
      "['influenced', 20979]\n",
      "['cinematographer', 20010]\n",
      "['directed', 19373]\n",
      "ns:business.employer.employees/ns:business.employment_tenure.person 10866\n",
      "['employer', 6161]\n",
      "['employ', 3211]\n",
      "['employed', 2054]\n",
      "ns:film.actor.film/ns:film.performance.character 12209\n",
      "['actor', 9219]\n",
      "['played', 2093]\n",
      "['play', 1235]\n",
      "ns:film.actor.film/ns:film.performance.film 29669\n",
      "['star', 27305]\n",
      "['cinematographer', 9077]\n",
      "['artdirector', 8351]\n",
      "ns:film.cinematographer.film 26135\n",
      "['cinematographer', 26135]\n",
      "['editor', 9188]\n",
      "['director', 8807]\n",
      "ns:film.director.film 42005\n",
      "['director', 26945]\n",
      "['cinematographer', 10995]\n",
      "['directed', 10386]\n",
      "ns:film.editor.film 41846\n",
      "['editor', 26590]\n",
      "['cinematographer', 11418]\n",
      "['edited', 10583]\n",
      "ns:film.film.cinematography 99\n",
      "['cinematographer', 99]\n",
      "['executiveproduced', 27]\n",
      "['director', 25]\n",
      "ns:film.film.costume_design_by 56\n",
      "['costumedesigner', 56]\n",
      "['edited', 15]\n",
      "['wrote', 13]\n",
      "ns:film.film.directed_by 31855\n",
      "['directed', 27909]\n",
      "['edited', 15802]\n",
      "['written', 15211]\n",
      "ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor 4208\n",
      "['distributed', 3455]\n",
      "['produced', 2433]\n",
      "['distribute', 742]\n",
      "ns:film.film.edited_by 31856\n",
      "['edited', 27680]\n",
      "['directed', 15800]\n",
      "['written', 15430]\n",
      "ns:film.film.executive_produced_by 31937\n",
      "['executiveproduced', 27274]\n",
      "['written', 14527]\n",
      "['directed', 14342]\n",
      "ns:film.film.film_art_direction_by 101\n",
      "['artdirector', 101]\n",
      "['produced', 25]\n",
      "['directed', 25]\n",
      "ns:film.film.prequel 6175\n",
      "['sequel', 6129]\n",
      "['directed', 1035]\n",
      "['edited', 978]\n",
      "ns:film.film.produced_by|ns:film.film.production_companies 30979\n",
      "['produced', 26718]\n",
      "['edited', 13778]\n",
      "['written', 13716]\n",
      "ns:film.film.sequel 6683\n",
      "['prequel', 6638]\n",
      "['directed', 1191]\n",
      "['edited', 1140]\n",
      "ns:film.film.starring/ns:film.performance.actor 4724\n",
      "['star', 3842]\n",
      "['starred', 940]\n",
      "['cinematographer', 649]\n",
      "ns:film.film.written_by 32180\n",
      "['written', 27840]\n",
      "['edited', 15529]\n",
      "['directed', 15357]\n",
      "ns:film.film_art_director.films_art_directed 22744\n",
      "['artdirector', 22744]\n",
      "['cinematographer', 8410]\n",
      "['editor', 8044]\n",
      "ns:film.film_costumer_designer.costume_design_for_film 18185\n",
      "['costumedesigner', 18185]\n",
      "['artdirector', 6372]\n",
      "['editor', 5952]\n",
      "ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film 4072\n",
      "['distributor', 2921]\n",
      "['producer', 1231]\n",
      "['distributed', 709]\n",
      "ns:film.producer.films_executive_produced 34794\n",
      "['executiveproducer', 21129]\n",
      "['executiveproduce', 8590]\n",
      "['executiveproduced', 8456]\n",
      "ns:film.producer.film|ns:film.production_company.films 37786\n",
      "['producer', 25645]\n",
      "['cinematographer', 9834]\n",
      "['artdirector', 9023]\n",
      "ns:film.writer.film 41572\n",
      "['writer', 26799]\n",
      "['cinematographer', 10884]\n",
      "['director', 9855]\n",
      "ns:influence.influence_node.influenced 17354\n",
      "['influenced', 9555]\n",
      "['influence', 7951]\n",
      "['marry', 4128]\n",
      "ns:influence.influence_node.influenced_by 25623\n",
      "['influenced', 20798]\n",
      "['influence', 5006]\n",
      "['married', 4368]\n",
      "ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company 2761\n",
      "['acquired', 2246]\n",
      "['employer', 622]\n",
      "['acquire', 540]\n",
      "ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired 2097\n",
      "['acquire', 1307]\n",
      "['acquired', 809]\n",
      "['employer', 459]\n",
      "ns:organization.organization.founders 8869\n",
      "['founded', 6556]\n",
      "['found', 1808]\n",
      "['founder', 1386]\n",
      "ns:organization.organization_founder.organizations_founded 21886\n",
      "['founder', 15014]\n",
      "['employee', 6644]\n",
      "['founded', 5550]\n",
      "ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child 15583\n",
      "['parent', 15374]\n",
      "['child', 2052]\n",
      "['spouse', 1840]\n",
      "ns:people.person.employment_history/ns:business.employment_tenure.company 24087\n",
      "['employee', 14106]\n",
      "['employed', 9027]\n",
      "['founder', 6701]\n",
      "ns:people.person.gender 30952\n",
      "['spouse', 4653]\n",
      "['sibling', 4261]\n",
      "['cinematographer', 3563]\n",
      "ns:people.person.nationality 64135\n",
      "['spouse', 7723]\n",
      "['produced', 7706]\n",
      "['directed', 7454]\n",
      "ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent 14946\n",
      "['child', 14747]\n",
      "['parent', 2041]\n",
      "['sibling', 1804]\n",
      "ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings 19568\n",
      "['sibling', 19568]\n",
      "['spouse', 2596]\n",
      "['directed', 1983]\n",
      "ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses 41566\n",
      "['spouse', 20224]\n",
      "['marry', 13456]\n",
      "['married', 10186]\n"
     ]
    }
   ],
   "source": [
    "def _fn(by):\n",
    "    for key, grp in groupby(sorted(([tok, [typ, c]] if by == 'tok' else [typ, [tok, c]]\n",
    "                                    for [tok, typ], c in both.items()), key=at(0)), at(0)):\n",
    "        _, c = zip(*grp)\n",
    "        print(key, (c_tok if by == 'tok' else c_rel)[key])\n",
    "        print(*islice(sorted(c, key=at(1), reverse=True), 3), sep='\\n')\n",
    "        \n",
    "_fn('tok')\n",
    "print()\n",
    "_fn('typ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP, NIL = '{SEP}', '{NIL}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0', '?x1', '?x2', '?x3', '?x4', '?x5']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isvar = lambda tok: tok.startswith('?x')\n",
    "idx2var = sorted(set(chain(filter(isvar, srcs), filter(isvar, dsts))))\n",
    "idx2var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{SEP}',\n",
       " '{NIL}',\n",
       " '?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " \"'s\",\n",
       " ',',\n",
       " 'American',\n",
       " 'British',\n",
       " 'Canadian',\n",
       " 'Chinese',\n",
       " 'Did',\n",
       " 'Dutch',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'Mexican',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Was',\n",
       " 'Were',\n",
       " 'What',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'a',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'artdirector',\n",
       " 'by',\n",
       " 'character',\n",
       " 'child',\n",
       " 'cinematographer',\n",
       " 'company',\n",
       " 'costumedesigner',\n",
       " 'countryofnationality',\n",
       " 'did',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'director',\n",
       " 'distribute',\n",
       " 'distributed',\n",
       " 'distributor',\n",
       " 'edit',\n",
       " 'edited',\n",
       " 'editor',\n",
       " 'employ',\n",
       " 'employed',\n",
       " 'employee',\n",
       " 'employer',\n",
       " 'executiveproduce',\n",
       " 'executiveproduced',\n",
       " 'executiveproducer',\n",
       " 'female',\n",
       " 'film',\n",
       " 'filmdirector',\n",
       " 'filmdistributor',\n",
       " 'filmeditor',\n",
       " 'filmproducer',\n",
       " 'found',\n",
       " 'founded',\n",
       " 'founder',\n",
       " 'gender',\n",
       " 'influence',\n",
       " 'influenced',\n",
       " 'male',\n",
       " 'married',\n",
       " 'marry',\n",
       " 'of',\n",
       " 'parent',\n",
       " 'person',\n",
       " 'play',\n",
       " 'played',\n",
       " 'prequel',\n",
       " 'produce',\n",
       " 'produced',\n",
       " 'producer',\n",
       " 'productioncompany',\n",
       " 'screenwriter',\n",
       " 'sequel',\n",
       " 'sibling',\n",
       " 'spouse',\n",
       " 'star',\n",
       " 'starred',\n",
       " 'that',\n",
       " 'was',\n",
       " 'were',\n",
       " 'whose',\n",
       " 'write',\n",
       " 'writer',\n",
       " 'written',\n",
       " 'wrote']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tok = [SEP, NIL] + idx2var + unique(df.rdd.flatMap(lambda r: r['questionPatternModEntities'].split(' ')))\n",
    "tok2idx = {tok : idx for idx, tok in enumerate(idx2tok)}\n",
    "idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{SEP}',\n",
       " '{NIL}',\n",
       " '?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " \"'s\",\n",
       " ',',\n",
       " 'Did',\n",
       " 'Was',\n",
       " 'Were',\n",
       " 'What',\n",
       " 'Which',\n",
       " 'Who',\n",
       " '[ADJECTIVE_SIMPLE]',\n",
       " '[NP_SIMPLE]',\n",
       " '[ROLE_SIMPLE]',\n",
       " '[VP_SIMPLE]',\n",
       " '[entity]',\n",
       " 'a',\n",
       " 'and',\n",
       " 'by',\n",
       " 'did',\n",
       " 'of',\n",
       " 'that',\n",
       " 'was',\n",
       " 'were',\n",
       " 'whose']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag = [SEP, NIL] + idx2var + unique(df.rdd.flatMap(lambda r: r['questionTemplate'].split(' ')))\n",
    "tag2idx = {tag : idx for idx, tag in enumerate(idx2tag)}\n",
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(re.compile(r'(?:\\[NP_SIMPLE\\]|\\[entity\\]|\\[ADJECTIVE_SIMPLE\\]|\\[VP_SIMPLE\\]|\\[ROLE_SIMPLE\\]) and (?:\\[NP_SIMPLE\\]|\\[entity\\]|\\[ADJECTIVE_SIMPLE\\]|\\[VP_SIMPLE\\]|\\[ROLE_SIMPLE\\])|(?:(?:\\[NP_SIMPLE\\]|\\[entity\\]|\\[ADJECTIVE_SIMPLE\\]|\\[VP_SIMPLE\\]|\\[ROLE_SIMPLE\\]) , )+and (?:\\[NP_SIMPLE\\]|\\[entity\\]|\\[ADJECTIVE_SIMPLE\\]|\\[VP_SIMPLE\\]|\\[ROLE_SIMPLE\\])',\n",
       " re.UNICODE),\n",
       " re.compile(r'\\[NP_SIMPLE\\] and \\[NP_SIMPLE\\]|(?:\\[NP_SIMPLE\\] , )+and \\[NP_SIMPLE\\]|\\[entity\\] and \\[entity\\]|(?:\\[entity\\] , )+and \\[entity\\]|\\[ADJECTIVE_SIMPLE\\] and \\[ADJECTIVE_SIMPLE\\]|(?:\\[ADJECTIVE_SIMPLE\\] , )+and \\[ADJECTIVE_SIMPLE\\]|\\[VP_SIMPLE\\] and \\[VP_SIMPLE\\]|(?:\\[VP_SIMPLE\\] , )+and \\[VP_SIMPLE\\]|\\[ROLE_SIMPLE\\] and \\[ROLE_SIMPLE\\]|(?:\\[ROLE_SIMPLE\\] , )+and \\[ROLE_SIMPLE\\]',\n",
       " re.UNICODE))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo = lambda r: sum(role in r for role in roles) == 1\n",
    "r = '(?:%s)' % '|'.join(fr'\\[{role[1 : -1]}\\]' for role in roles)\n",
    "p0 = re.compile(fr'{r} and {r}|(?:{r} , )+and {r}')\n",
    "p1 = re.compile('|'.join(fr'{r} and {r}|(?:{r} , )+and {r}' for r in [fr'\\[{role[1 : -1]}\\]' for role in roles]))\n",
    "p0, p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[VP_SIMPLE] and [VP_SIMPLE]']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p0, df.rdd.map(lambda r: r['questionTemplate']).take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda r: r['questionTemplate']).map(lambda r: sorted(filter(homo, re.findall(p0, r))) != sorted(re.findall(p1, r))).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b807280a3b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questionTemplate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questionTemplate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'collect' is not defined"
     ]
    }
   ],
   "source": [
    "indices = collect(df.rdd.filter(lambda r: sorted(filter(homo, re.findall(p0, r['questionTemplate']))) != sorted(re.findall(p1, r['questionTemplate']))).map(lambda r: r['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    for k, v in splits[f'mcd{i}'].items():\n",
    "        print(k, np.sum(np.isin(indices, v)) / len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.map(lambda r: r['questionTemplate']).filter(lambda r: sorted(filter(homo, re.findall(p0, r))) != sorted(re.findall(p1, r))).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.map(lambda r: r['questionTemplate']).filter(lambda r: sorted(filter(homo, re.findall(p0, r))) != sorted(re.findall(p1, r))).map(lambda r: sorted(filter(homo, re.findall(p0, r)))).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.map(lambda r: r['questionTemplate']).filter(lambda r: sorted(filter(homo, re.findall(p0, r))) != sorted(re.findall(p1, r))).map(lambda r: sorted(re.findall(p1, r))).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.map(lambda r: r['questionTemplate']).map(lambda r: all(map(homo, re.findall(p1, r)))).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = '(?:%s)' % '|'.join(fr'\\[{role[1 : -1]}\\]' for role in roles)\n",
    "# p = re.compile(fr'{r} and {r}|(?:{r} , )+and {r}')\n",
    "p = re.compile('|'.join(fr'{r} and {r}|(?:{r} , )+and {r}' for r in [fr'\\[{role[1 : -1]}\\]' for role in roles]))\n",
    "def grp_by_tag(tags):\n",
    "    lens = np.array(list(map(len, tags)))\n",
    "    ends = np.cumsum(lens) + np.arange(len(tags))\n",
    "    starts = ends - lens\n",
    "\n",
    "    t = ' '.join(tags)\n",
    "    homo = lambda s: sum(role in s for role in roles) == 1\n",
    "    matches = [m for m in re.finditer(p, t) if homo(m.group())]\n",
    "    if not matches:\n",
    "        grps = [[i] for i in range(len(tags))]\n",
    "        return grps\n",
    "    \n",
    "    m_start, m_end = zip(*([m.start(), m.end()] for m in matches))\n",
    "    hit = False\n",
    "    grps = []\n",
    "    for idx, [start, end] in enumerate(zip(starts, ends)):\n",
    "        if start in m_start:\n",
    "            hit = True\n",
    "            grps.append([])\n",
    "        if hit:\n",
    "            grps[-1].append(idx)\n",
    "        else:\n",
    "            grps.append([idx])\n",
    "        if end in m_end:\n",
    "            hit = False\n",
    "    \n",
    "    for start, end, grp in zip(m_start, m_end, (grp for grp in grps if len(grp) > 1)):\n",
    "        assert t[start : end] == ' '.join(tags[idx] for idx in grp)\n",
    "\n",
    "    return grps\n",
    "\n",
    "def _mapper(r):\n",
    "    rels = list(map(find_rel, r['sparqlPatternModEntities'].split('\\n')[1 : -1]))\n",
    "    srcs, typs, dsts = zip(*rels)\n",
    "    ents = sorted({x for x in chain(srcs, dsts) if re.match('M\\d', x) or re.match('\\?x\\d', x)})\n",
    "\n",
    "    tail = [SEP] + sorted(ent for ent in ents if ent.startswith('?x')) + [NIL]\n",
    "    toks = r['questionPatternModEntities'].split(' ') + tail\n",
    "    tags = r['questionTemplate'].split(' ') + tail\n",
    "    grps = grp_by_tag(tags)\n",
    "\n",
    "    seq = [tag2idx[tags[idx]] for idx, *_ in grps]\n",
    "    mem = [[tok2idx[toks[grp[0]]]] if len(grp) == 1 else\n",
    "           [tok2idx[toks[idx]] for idx in grp if tags[idx] in roles] for grp in grps]\n",
    "    \n",
    "    ent2grp = {}\n",
    "    for idx, tok in zip(chain(*(len(grp) * [idx] for idx, grp in enumerate(grps))), toks):\n",
    "        if tok in ents:\n",
    "            ent2grp[tok] = idx\n",
    "    idx2grp = sorted(set(ent2grp.values()))\n",
    "    ent2idx = {ent: idx2grp.index(ent2grp[ent]) for ent in ents}\n",
    "    _, idx2ent = zip(*sorted(ent2idx.items(), key=at(1)))\n",
    "    \n",
    "    # filters\n",
    "    filters = [[ent2idx[src], ent2idx[dst]] for src, typ, dst in rels if typ == '!=']\n",
    "    \n",
    "    # attributes\n",
    "    ent2attr = np.zeros([len(idx2grp), len(idx2attr)])\n",
    "    for src, _, dst in rels:\n",
    "        if dst in idx2attr:\n",
    "            ent2attr[ent2idx[src], idx2attr.index(dst)] = 1\n",
    "\n",
    "    # groundable relations\n",
    "    gr_rels = [[ent2idx[src], ent2idx[dst], idx2typ.index(typ)] for src, typ, dst in rels if typ in idx2typ]\n",
    "\n",
    "    return filters, ent2attr, gr_rels, seq, mem, idx2grp\n",
    "\n",
    "dat = {}\n",
    "collect = lambda rdd: np.array(rdd.collect())\n",
    "\n",
    "# print(_mapper(df.rdd.take(10)[-1]))\n",
    "# _mapper(df.where(df.index == 13).rdd.take(1)[0])\n",
    "rdd = df.rdd.map(_mapper).cache()\n",
    "dat['n_filter'] = collect(rdd.map(at(0)).map(len))\n",
    "dat['filter'] = collect(rdd.flatMap(at(0)))\n",
    "dat['attr'] = np.vstack(rdd.map(at(1)).collect())\n",
    "dat['n_rel'] = collect(rdd.map(at(2)).map(len))\n",
    "dat['src'] = collect(rdd.flatMap(at(2)).map(at(0)))\n",
    "dat['dst'] = collect(rdd.flatMap(at(2)).map(at(1)))\n",
    "dat['typ'] = collect(rdd.flatMap(at(2)).map(at(2)))\n",
    "dat['seq'] = collect(rdd.flatMap(at(3)))\n",
    "dat['n_grp'] = collect(rdd.map(at(4)).map(len))\n",
    "dat['n_mem'] = collect(rdd.flatMap(at(4)).map(len))\n",
    "dat['mem'] = collect(rdd.flatMap(at(4)).flatMap(lambda r: r))\n",
    "dat['n'] = collect(rdd.map(at(5)).map(len))\n",
    "dat['idx2grp'] = collect(rdd.flatMap(at(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = \"Did [entity] [VP_SIMPLE] [entity] 's [ROLE_SIMPLE] , [ROLE_SIMPLE] , [ROLE_SIMPLE] , [ROLE_SIMPLE] , [ROLE_SIMPLE] , and [ROLE_SIMPLE] and [VP_SIMPLE] [entity]\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = [[tags[idx] for idx in grp] for grp in grp_by_tag(tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, grps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dat['typ'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([idx2tok, tok2idx], open(f'{output_dir}/tok-vocab.pickle', 'wb'))\n",
    "pickle.dump([idx2tag, tag2idx], open(f'{output_dir}/tag-vocab.pickle', 'wb'))\n",
    "pickle.dump([idx2typ, typ2idx], open(f'{output_dir}/typ-vocab.pickle', 'wb'))\n",
    "np.savez(f'{output_dir}/data', **dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mapper(r):\n",
    "    r, [filters, ent2attr, gr_rels, seq, mem, idx2grp] = r\n",
    "    rels = set()\n",
    "    for src, dst, typ in gr_rels:\n",
    "        for x, y in product(mem[idx2grp[src]], mem[idx2grp[dst]]):\n",
    "            rels.add(f'{idx2tok[x]} {idx2typ[typ]} {idx2tok[y]}')\n",
    "#     print(sorted(rels))\n",
    "    isrel = lambda r: all(s not in r for s in ['!=', ' a ', ' ns:people.person.gender', ' ns:people.person.nationality'])\n",
    "    xs = ''.join(r['sparqlPatternModEntities'].split('\\n')[1 : -1]).split(' .')\n",
    "#     print(sorted(filter(isrel, xs)))\n",
    "    return sorted(rels), sorted(filter(isrel, xs)), r['questionPatternModEntities'], r['questionTemplate'], r['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['?x0 ns:film.actor.film/ns:film.performance.character M1',\n",
       "  '?x0 ns:film.editor.film M0',\n",
       "  '?x0 ns:film.producer.film|ns:film.production_company.films M0'],\n",
       " ['?x0 ns:film.actor.film/ns:film.performance.character M1',\n",
       "  '?x0 ns:film.editor.film M0',\n",
       "  '?x0 ns:film.producer.film|ns:film.production_company.films M0'],\n",
       " \"Did M1 's female actor edit and produce M0\",\n",
       " \"Did [entity] 's [ADJECTIVE_SIMPLE] [ROLE_SIMPLE] [VP_SIMPLE] and [VP_SIMPLE] [entity]\",\n",
       " 0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mapper(df.rdd.zip(rdd).take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 314.0 failed 1 times, most recent failure: Lost task 0.0 in stage 314.0 (TID 24432, havoc.millennium.berkeley.edu, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1440, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-114-361e59757ddd>\", line 2, in _mapper\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD$$$Lambda$7680/1142513594.apply(Unknown Source)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext$$Lambda$1313/612188285.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1275/458075417.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7600/724451276.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7597/1084380903.apply(Unknown Source)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor1147.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1440, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-114-361e59757ddd>\", line 2, in _mapper\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD$$$Lambda$7680/1142513594.apply(Unknown Source)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext$$Lambda$1313/612188285.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1275/458075417.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-ba7777d17dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 314.0 failed 1 times, most recent failure: Lost task 0.0 in stage 314.0 (TID 24432, havoc.millennium.berkeley.edu, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1440, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-114-361e59757ddd>\", line 2, in _mapper\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD$$$Lambda$7680/1142513594.apply(Unknown Source)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext$$Lambda$1313/612188285.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1275/458075417.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7600/724451276.apply(Unknown Source)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler$$Lambda$7597/1084380903.apply(Unknown Source)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor1147.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/data/yu_gai/anaconda3/envs/cfq-yu/lib/python3.8/site-packages/pyspark/rdd.py\", line 1440, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/data/yu_gai/anaconda3/envs/ee227/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-114-361e59757ddd>\", line 2, in _mapper\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:154)\n\tat org.apache.spark.api.python.PythonRDD$$$Lambda$7680/1142513594.apply(Unknown Source)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext$$Lambda$1313/612188285.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1275/458075417.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.where(df.index == 13).rdd.map(_mapper).take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.zip(rdd).map(_mapper).filter(lambda r: r[0] != r[1]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['?x0 ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   '?x2 ns:film.actor.film/ns:film.performance.film M1',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M4 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M4 ns:business.employer.employees/ns:business.employment_tenure.person M3'],\n",
       "  ['?x0 ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   '?x2 ns:film.actor.film/ns:film.performance.film M1',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M4 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M4 ns:business.employer.employees/ns:business.employment_tenure.person M3'],\n",
       "  \"Did M2 , M4 , and M2 employ M3 and employ M1 's star 's American spouse 's sibling\",\n",
       "  \"Did [entity] , [entity] , and [entity] [VP_SIMPLE] [entity] and [VP_SIMPLE] [entity] 's [ROLE_SIMPLE] 's [ADJECTIVE_SIMPLE] [ROLE_SIMPLE] 's [ROLE_SIMPLE]\",\n",
       "  1666),\n",
       " (['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M4',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M5'],\n",
       "  ['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M4',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M5'],\n",
       "  \"Did M1 employ M2 , M2 , and M3 , employ a filmdirector 's parent , and employ M4 and M5\",\n",
       "  \"Did [entity] [VP_SIMPLE] [entity] , [entity] , and [entity] , [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE] , and [VP_SIMPLE] [entity] and [entity]\",\n",
       "  3001),\n",
       " (['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x0',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x3'],\n",
       "  ['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x0',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x0',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x3',\n",
       "   'M3 ns:film.film.starring/ns:film.performance.actor ?x3'],\n",
       "  \"Did M3 and M3 star a Spanish filmdirector 's spouse 's parent and star a person\",\n",
       "  \"Did [entity] and [entity] [VP_SIMPLE] a [ADJECTIVE_SIMPLE] [NP_SIMPLE] 's [ROLE_SIMPLE] 's [ROLE_SIMPLE] and [VP_SIMPLE] a [NP_SIMPLE]\",\n",
       "  3845),\n",
       " (['?x0 ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings ?x1',\n",
       "   'M1 ns:influence.influence_node.influenced M2',\n",
       "   'M1 ns:influence.influence_node.influenced M3',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0'],\n",
       "  ['?x0 ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings ?x1',\n",
       "   'M1 ns:influence.influence_node.influenced M2',\n",
       "   'M1 ns:influence.influence_node.influenced M2',\n",
       "   'M1 ns:influence.influence_node.influenced M3',\n",
       "   'M1 ns:influence.influence_node.influenced M3',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0'],\n",
       "  \"Did M1 and M1 influence M2 and M3 and marry a filmproducer 's sibling\",\n",
       "  \"Did [entity] and [entity] [VP_SIMPLE] [entity] and [entity] and [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE]\",\n",
       "  5391),\n",
       " (['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2'],\n",
       "  ['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2'],\n",
       "  \"Did M1 and M1 marry a costumedesigner 's spouse and marry M2\",\n",
       "  \"Did [entity] and [entity] [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE] and [VP_SIMPLE] [entity]\",\n",
       "  6454),\n",
       " (['?x0 ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent ?x1',\n",
       "   '?x1 ns:film.director.film M1',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M4',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M5'],\n",
       "  ['?x0 ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent ?x1',\n",
       "   '?x1 ns:film.director.film M1',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M3',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M4',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M4',\n",
       "   'M2 ns:business.employer.employees/ns:business.employment_tenure.person M5'],\n",
       "  \"Did M2 employ M3 , M4 , M5 , and M4 and employ M1 's Japanese director 's child\",\n",
       "  \"Did [entity] [VP_SIMPLE] [entity] , [entity] , [entity] , and [entity] and [VP_SIMPLE] [entity] 's [ADJECTIVE_SIMPLE] [ROLE_SIMPLE] 's [ROLE_SIMPLE]\",\n",
       "  7953),\n",
       " (['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   '?x1 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x2',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person M2'],\n",
       "  ['?x0 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x1',\n",
       "   '?x1 ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child ?x2',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M1 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person ?x0',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person M2',\n",
       "   'M3 ns:business.employer.employees/ns:business.employment_tenure.person M2'],\n",
       "  \"Did M1 , M3 , and M3 employ M2 and employ a filmdirector 's parent 's parent\",\n",
       "  \"Did [entity] , [entity] , and [entity] [VP_SIMPLE] [entity] and [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE] 's [ROLE_SIMPLE]\",\n",
       "  9994),\n",
       " (['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M3 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M3 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M4'],\n",
       "  ['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M3 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M3 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M4',\n",
       "   'M3 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M4'],\n",
       "  \"Did M3 marry a Italian cinematographer 's American spouse and marry M4 and M4\",\n",
       "  \"Did [entity] [VP_SIMPLE] a [ADJECTIVE_SIMPLE] [NP_SIMPLE] 's [ADJECTIVE_SIMPLE] [ROLE_SIMPLE] and [VP_SIMPLE] [entity] and [entity]\",\n",
       "  11133),\n",
       " (['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   'M2 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0'],\n",
       "  ['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   '?x1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x2',\n",
       "   'M2 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M2 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0'],\n",
       "  \"Did M2 and M2 marry a artdirector 's spouse 's Italian spouse\",\n",
       "  \"Did [entity] and [entity] [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE] 's [ADJECTIVE_SIMPLE] [ROLE_SIMPLE]\",\n",
       "  14128),\n",
       " (['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M3'],\n",
       "  ['?x0 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x1',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses ?x0',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M2',\n",
       "   'M1 ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses M3'],\n",
       "  \"Did M1 marry M2 , marry M2 , marry M3 , and marry a artdirector 's spouse\",\n",
       "  \"Did [entity] [VP_SIMPLE] [entity] , [VP_SIMPLE] [entity] , [VP_SIMPLE] [entity] , and [VP_SIMPLE] a [NP_SIMPLE] 's [ROLE_SIMPLE]\",\n",
       "  14256)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.zip(rdd).map(_mapper).filter(lambda r: r[0] != r[1]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0' == 'M2 ns:business.employer.employees/ns:business.employment_tenure.person ?x0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.actor.film/ns:film.performance.character M1 .\n",
      "?x0 ns:film.editor.film M0 .\n",
      "?x0 ns:film.producer.film|ns:film.production_company.films M0 .\n",
      "?x0 ns:people.person.gender ns:m.02zsn\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(df.rdd.map(lambda r: r['sparqlPatternModEntities']).take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "tok_rdd = df.rdd.map(lambda r: [tok2idx[tok] for tok in r['questionPatternModEntities'].split(' ')])\n",
    "d['seq'] = fcollect(tok_rdd)\n",
    "d['n_tok'] = collect(tok_rdd.map(len))\n",
    "d['n_var'] = collect(df.rdd.map(lambda r: len(set(re.findall(r'\\?x[0-9]', r['sparqlPatternModEntities'])))))\n",
    "np.savez(f'{output_dir}/nvar', **d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
