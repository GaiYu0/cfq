{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from operator import *\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CFQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complexityMeasures',\n",
       " 'expectedResponse',\n",
       " 'expectedResponseWithMids',\n",
       " 'question',\n",
       " 'questionPatternModEntities',\n",
       " 'questionWithBrackets',\n",
       " 'questionWithMids',\n",
       " 'ruleIds',\n",
       " 'ruleTree',\n",
       " 'sparql',\n",
       " 'sparqlPattern',\n",
       " 'sparqlPatternModEntities']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlCtx.read.parquet('/data/yu_gai/cfq/dataset.parquet/')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Were M2 and M5 executive produced by a British executive producer of M0 and executive produced by M3 and M4\n",
      "SELECT count(*) WHERE {\n",
      "?x0 ns:film.producer.films_executive_produced M0 .\n",
      "?x0 ns:people.person.nationality ns:m.07ssc .\n",
      "M2 ns:film.film.executive_produced_by ?x0 .\n",
      "M2 ns:film.film.executive_produced_by M3 .\n",
      "M2 ns:film.film.executive_produced_by M4 .\n",
      "M5 ns:film.film.executive_produced_by ?x0 .\n",
      "M5 ns:film.film.executive_produced_by M3 .\n",
      "M5 ns:film.film.executive_produced_by M4\n",
      "}\n",
      "\n",
      "Were M1 , M2 , and M3 influenced by a film producer\n",
      "SELECT count(*) WHERE {\n",
      "?x0 a ns:film.producer .\n",
      "M1 ns:influence.influence_node.influenced_by ?x0 .\n",
      "M2 ns:influence.influence_node.influenced_by ?x0 .\n",
      "M3 ns:influence.influence_node.influenced_by ?x0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "rs = df.rdd.map(lambda r: [r['questionPatternModEntities'], r['sparqlPatternModEntities']]).take(n)\n",
    "for i, [question, query] in enumerate(rs):\n",
    "    print(question)\n",
    "    print(query)\n",
    "    if i < n - 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELECT', 'FILTER', 'WHERE', 'DISTINCT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'[A-Z]+')\n",
    "df.rdd.flatMap(lambda r: re.findall(p, r['sparql'])).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SELECT count(*) WHERE {', 'SELECT DISTINCT ?x0 WHERE {'], ['}'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = df.rdd.map(lambda r: r['sparqlPatternModEntities'].split('\\n')).cache()\n",
    "rdd.map(lambda r: r[0]).distinct().collect(), rdd.map(lambda r: r[-1]).distinct().collect()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL TRIPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = rdd.flatMap(lambda r: [l for l in r[1 : -1] if 'FILTER' not in l]).distinct()\n",
    "p = re.compile(r'^([^ ]+) ([^ ]+) ([^ ]+)( .)?$')\n",
    "triples = triples.map(lambda r: re.findall(p, r)).cache()\n",
    "assert triples.map(lambda r: len(r) == 1).reduce(and_)\n",
    "triples = triples.map(lambda r: r[0])\n",
    "assert triples.map(lambda r: r[-1] in ['', ' .']).reduce(and_)  # conjunction only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(triples.map(lambda r: r[0]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^ns:people.person.gender',\n",
       " '^ns:people.person.nationality',\n",
       " 'a',\n",
       " 'ns:business.employer.employees/ns:business.employment_tenure.person',\n",
       " 'ns:film.actor.film/ns:film.performance.character',\n",
       " 'ns:film.actor.film/ns:film.performance.film',\n",
       " 'ns:film.cinematographer.film',\n",
       " 'ns:film.director.film',\n",
       " 'ns:film.editor.film',\n",
       " 'ns:film.film.cinematography',\n",
       " 'ns:film.film.costume_design_by',\n",
       " 'ns:film.film.directed_by',\n",
       " 'ns:film.film.distributors/ns:film.film_film_distributor_relationship.distributor',\n",
       " 'ns:film.film.edited_by',\n",
       " 'ns:film.film.executive_produced_by',\n",
       " 'ns:film.film.film_art_direction_by',\n",
       " 'ns:film.film.prequel',\n",
       " 'ns:film.film.produced_by|ns:film.film.production_companies',\n",
       " 'ns:film.film.sequel',\n",
       " 'ns:film.film.starring/ns:film.performance.actor',\n",
       " 'ns:film.film.written_by',\n",
       " 'ns:film.film_art_director.films_art_directed',\n",
       " 'ns:film.film_costumer_designer.costume_design_for_film',\n",
       " 'ns:film.film_distributor.films_distributed/ns:film.film_film_distributor_relationship.film',\n",
       " 'ns:film.producer.films_executive_produced',\n",
       " 'ns:film.producer.film|ns:film.production_company.films',\n",
       " 'ns:film.writer.film',\n",
       " 'ns:influence.influence_node.influenced',\n",
       " 'ns:influence.influence_node.influenced_by',\n",
       " 'ns:organization.organization.acquired_by/ns:business.acquisition.acquiring_company',\n",
       " 'ns:organization.organization.companies_acquired/ns:business.acquisition.company_acquired',\n",
       " 'ns:organization.organization.founders',\n",
       " 'ns:organization.organization_founder.organizations_founded',\n",
       " 'ns:people.person.children|ns:fictional_universe.fictional_character.children|ns:organization.organization.child/ns:organization.organization_relationship.child',\n",
       " 'ns:people.person.employment_history/ns:business.employment_tenure.company',\n",
       " 'ns:people.person.gender',\n",
       " 'ns:people.person.nationality',\n",
       " 'ns:people.person.parents|ns:fictional_universe.fictional_character.parents|ns:organization.organization.parent/ns:organization.organization_relationship.parent',\n",
       " 'ns:people.person.sibling_s/ns:people.sibling_relationship.sibling|ns:fictional_universe.fictional_character.siblings/ns:fictional_universe.sibling_relationship_of_fictional_characters.siblings',\n",
       " 'ns:people.person.spouse_s/ns:people.marriage.spouse|ns:fictional_universe.fictional_character.married_to/ns:fictional_universe.marriage_of_fictional_characters.spouses']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(triples.map(lambda r: r[1]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'ns:business.employer',\n",
       " 'ns:fictional_universe.fictional_character',\n",
       " 'ns:film.actor',\n",
       " 'ns:film.cinematographer',\n",
       " 'ns:film.director',\n",
       " 'ns:film.editor',\n",
       " 'ns:film.film',\n",
       " 'ns:film.film_art_director',\n",
       " 'ns:film.film_costumer_designer',\n",
       " 'ns:film.film_distributor',\n",
       " 'ns:film.producer',\n",
       " 'ns:film.production_company',\n",
       " 'ns:film.writer',\n",
       " 'ns:m.02zsn',\n",
       " 'ns:m.0345h',\n",
       " 'ns:m.03_3d',\n",
       " 'ns:m.03rjj',\n",
       " 'ns:m.059j2',\n",
       " 'ns:m.05zppz',\n",
       " 'ns:m.06mkj',\n",
       " 'ns:m.07ssc',\n",
       " 'ns:m.09c7w0',\n",
       " 'ns:m.0b90_r',\n",
       " 'ns:m.0d05w3',\n",
       " 'ns:m.0d060g',\n",
       " 'ns:m.0d0vqn',\n",
       " 'ns:m.0f8l9c',\n",
       " 'ns:people.person']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(triples.map(lambda r: r[2]).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'ns:m.02zsn',\n",
       " 'ns:m.0345h',\n",
       " 'ns:m.03_3d',\n",
       " 'ns:m.03rjj',\n",
       " 'ns:m.059j2',\n",
       " 'ns:m.05zppz',\n",
       " 'ns:m.06mkj',\n",
       " 'ns:m.07ssc',\n",
       " 'ns:m.09c7w0',\n",
       " 'ns:m.0b90_r',\n",
       " 'ns:m.0d05w3',\n",
       " 'ns:m.0d060g',\n",
       " 'ns:m.0d0vqn',\n",
       " 'ns:m.0f8l9c']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(triples.filter(lambda r: r[1] != 'a').map(lambda r: r[2]).distinct().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ns:people.person.gender', 'ns:people.person.nationality']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples.filter(lambda r: r[1] != 'a' and r[2].startswith('ns')).map(lambda r: r[1]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Instance of\" triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ = xs.filter(lambda r: r[0][1] == 'a').map(lambda r: r[0]).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(is_.map(lambda r: r[0]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ns:business.employer',\n",
       " 'ns:fictional_universe.fictional_character',\n",
       " 'ns:film.actor',\n",
       " 'ns:film.cinematographer',\n",
       " 'ns:film.director',\n",
       " 'ns:film.editor',\n",
       " 'ns:film.film',\n",
       " 'ns:film.film_art_director',\n",
       " 'ns:film.film_costumer_designer',\n",
       " 'ns:film.film_distributor',\n",
       " 'ns:film.producer',\n",
       " 'ns:film.production_company',\n",
       " 'ns:film.writer',\n",
       " 'ns:people.person']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(is_.map(lambda r: r[2]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = rdd.flatMap(lambda r: [l for l in r if 'FILTER' in l]).distinct()\n",
    "p = re.compile(r'^FILTER \\( ([^ ]+) != ([^ ]+) \\)( .)?$')  # not equal only\n",
    "xs = filters.map(lambda r: re.findall(p, r)).cache()\n",
    "assert xs.map(lambda r: len(r) == 1).reduce(and_)\n",
    "assert xs.map(lambda r: r[0][-1] in ['', ' .']).reduce(and_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(xs.map(lambda r: r[0][0]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?x0',\n",
       " '?x1',\n",
       " '?x2',\n",
       " '?x3',\n",
       " '?x4',\n",
       " '?x5',\n",
       " 'M0',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(xs.map(lambda r: r[0][1]).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95743, 11968, 11968, 239357)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_id = 'mcd1'\n",
    "split = json.load(open(f'/data/yu_gai/cfq/splits/{split_id}.json'))\n",
    "np.savez(f'/data/yu_gai/cfq/splits/{split_id}', **{k : np.array(v) for k, v in split.items()})\n",
    "len(split['trainIdxs']), len(split['devIdxs']), len(split['testIdxs']), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r\"^([A-Za-z0-9,']+[ ]?)+$\")\n",
    "df.rdd.map(lambda r: re.match(p, r['questionPatternModEntities']).string).zip(df.rdd.map(lambda r: r['questionPatternModEntities'])).map(lambda r: r[0] == r[1]).reduce(and_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "get = lambda rdd, i: rdd.map(lambda r: r[i])\n",
    "collect = lambda rdd: np.array(rdd.collect())\n",
    "fcollect = lambda rdd: np.array(rdd.flatMap(lambda r: r).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(r):\n",
    "    toks = r['questionPatternModEntities'].split(' ')\n",
    "    entities = sorted(set(re.findall(r'M[0-0]', r['questionPatternModEntities'])))\n",
    "    variables = sorted(set(re.findall(r'\\?x[0-9]', r['sparqlPatternModEntities'])))\n",
    "    concepts = []\n",
    "    for line in r['sparqlPatternModEntities'].split('\\n')[1 : -1]:\n",
    "        if 'FILTER' not in line:\n",
    "            [[concept, *_]] = re.findall(r'^[^ ]+ [^ ]+ ([^ ]+)( .)?$', line)\n",
    "            if concept.startswith('ns:'):\n",
    "                concepts.append(concept)\n",
    "    concepts = sorted(set(concepts))\n",
    "    seq = toks + concepts + variables\n",
    "    isconcept = len(toks) * [False] + len(concepts) * [True] + len(variables) * [False]\n",
    "    isvariable = len(toks) * [False] + len(concepts) * [False] + len(variables) * [True]\n",
    "    return seq, isconcept, isvariable\n",
    "\n",
    "rdd = df.rdd.map(mapper).cache()\n",
    "seq_rdd, isconcept_rdd, isvariable_rdd = get(rdd, 0).cache(), get(rdd, 1), get(rdd, 2)\n",
    "idx2tok = seq.flatMap(lambda r: r).distinct().collect() + ['[PAD]']\n",
    "tok2idx = dict(map(reversed, enumerate(idx2tok)))\n",
    "\n",
    "d['n_tok'] = np.array(seq_rdd.map(len).collect())\n",
    "d['seq'] = fcollect(seq_rdd.map(lambda r: [tok2id[tok] for tok in r]))\n",
    "d['isconcept'], d['isvariable'] = fcollect(isconcept_rdd), fcollect(isvariable_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = sorted(tok for tok in id2tok if re.match(r'^M[0-9]$', tok))\n",
    "concepts = sorted(tok for tok in id2tok if tok.startswith('ns:'))\n",
    "variables = sorted(tok for tok in id2tok if re.match(r'^\\?x[0-9]$', tok))\n",
    "sp_toks = sc.broadcast(set(entities + concepts + variables))\n",
    "def mapper(r):\n",
    "    d = defaultdict(list)\n",
    "    for i, tok in enumerate(r):\n",
    "        if tok in sp_toks.value:\n",
    "            d[tok].append(i)\n",
    "\n",
    "    n = len(d)\n",
    "    n_idx = [len(d[k]) for k in sorted(d)]\n",
    "    idx = sum((d[k] for k in sorted(d)), [])\n",
    "\n",
    "    return n, n_idx, idx\n",
    "\n",
    "rdd = seq_rdd.map(mapper).cache()\n",
    "d['n'] = collect(get(rdd, 0))\n",
    "d['n_idx'] = fcollect(get(rdd, 1))\n",
    "d['idx'] = fcollect(get(rdd, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(r):\n",
    "    src, rel, dst = [], [], []\n",
    "    for line in r['sparqlPatternModEntities'].split('\\n')[1 : -1]:\n",
    "        if 'FILTER' in line:\n",
    "            [[src_, dst_, *_]] = re.findall(r'^FILTER \\( ([^ ]+) != ([^ ]+) \\)( .)?$', line)\n",
    "            src.append(src_)\n",
    "            rel.append('!=')\n",
    "            dst.append(dst_)\n",
    "        else:\n",
    "            [[src_, rel_, dst_, *_]] = re.findall(r'^([^ ]+) ([^ ]+) ([^ ]+)( .)?$', line)\n",
    "            src.append(src_)\n",
    "            rel.append(rel_)\n",
    "            dst.append(dst_)\n",
    "\n",
    "    u, inv = np.unique(src + dst, return_inverse=True)\n",
    "    src, dst = np.split(np.arange(len(u))[inv], 2)\n",
    "    return src, rel, dst\n",
    "\n",
    "rdd = df.rdd.map(mapper).cache()\n",
    "d['src'], d['dst'] = fcollect(get(rdd, 0)), fcollect(get(rdd, 2))\n",
    "rel_rdd = get(rdd, 1).cache()\n",
    "d['m'] = collect(rel_rdd.map(len))\n",
    "rel_rdd = rel_rdd.flatMap(lambda r: r).cache()\n",
    "idx2rel = sorted(rel_rdd.distinct().collect())\n",
    "rel2idx = {rel : idx for idx, rel in enumerate(idx2rel)}\n",
    "d['rel'] = collect(rel_rdd.map(lambda r: rel2idx[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([idx2tok, tok2idx], open(f'/data/yu_gai/cfq/vocab.pickle', 'wb'))\n",
    "np.savez('/data/yu_gai/cfq/data', **d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
